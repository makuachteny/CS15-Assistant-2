I always kind of remember what it was. Like. This is when you grew up. It's like. Oh. Yeah. You know this? Yeah. That was like four times. It's like an array. Like, you know, I did four. He was. Like, you know, actually the actual like. I said it's a way to like. Put out. It was like an. Inside of the apple. Just like a video on it. It's like. Oh, yeah. That's awesome. Yeah, yeah. Okay. Now. No. I went to the I had to do my interviews and then I looked after the. Higher ups in the universe to do it all. I think it's like if our tendency for further exams was like the neighbor to have the noble like, it would be like they were just like like I'm waiting in the exam, like in this example. That's a hard one to find. There's no other paths. So they go back and that's. It for. Me to clarify. All right. Cool. Slowly. But everybody's doing pretty good. I know the lab.

Was good.

Traversing grass. Um, yeah. So.

As I tried to indicate before, graphs are enormously common in real life and therefore also in job interviews and on final exams. And so, um, it's worth, uh, is there worth understanding? And there were some effort. Um. Interesting fact. Oh, wait, that interesting fact. Um, when you're out in the world, when someone has a problem to solve, they almost never come to you and say, I have a graph with vertices and edges. They say things like, I've got a great idea for, for, um, for a social website that's based on this, and people are going to be able to connect over all kinds of things, and it would be your job as the computer scientist in the group to say, I can model that with a graph. Um, oh, don't do this to me. Let's see, I said stage laptop.

Emphasizes. Response. So.

I said, okay, well, I'm messing around with this. Um. Some of you may have heard about this, uh, uh, committee to to recommend whether Tufts should have a statement of institutional neutrality. Have you heard about this? Um, turns out I'm on that committee. Um, and so I know something about what's going on. Um, one thing that's happened is we decided at our meeting earlier this week is we want to try to have listening sessions, um, before the semester ends, which is like saying. So, um, look for next week in particular, and we're going to have listening sessions with, uh, faculty, staff and students. Um, and so there's one session that we want to do that's devoted to getting student input. Um, it turns out that this has been around for a while. Um, it actually was a thing from the it was a request from the faculty senate, like last April or something. So they finally got around to forming a committee a few like a month ago. And we've met four times and we haven't reached any conclusion yet. What we've all done and said, what the heck are these things? And we've read a few dozen positive and negative examples and we're just sort of gathering information. And so the next phase is to gather information from everybody else. Um, now that we have a little bit of a better sense of what's being asked. Um, and I would really like to be able to use my computer in this room. This would this would really be nice if I could do that. Anybody? All right. Well, failing that, what can I do? I can get the slides up in four up format. I stopped doing that. I continue to do that. Oh, great. So now the. Username and password is what is it. Anybody know. Those are all zoom.

They should be only for actual ones.

Oh, yeah. It's down. It was behind my screen. That's why it comes in.

Okay.

And you password is very nice. But incorrect. What did I get wrong? Let's try this again. This is fascinating.

Okay. This is. It's. Always been someone's. House.

I just have to remember to log out. Because I don't have the slides and usable format.

This is really annoying. To me. So, like, this time we're laughing. It's by a certain girl group. What is this? It's. Some questions. All right. Let's go. You are not alone. I'm not. You're not, you're not. You're not doing anything. What do you mean? I'm just saying you're waiting. Yeah. I'm not a simple retail. Oh, that's what you know. I don't know what that's actually. It's like on the 19th, right? Yeah. Oh 17 okay, I confuse 22. Either way, I didn't look like my last one. Right. Oh my gosh. Yeah. Yeah. So that's crazy. I was like. Oh, yeah. Oh. It's just. Oh, yeah. Yeah, I always have. Every year, like, every year. It's the worst. I'm not even. Oh, yeah. Yeah. Cause I'm really into Ivy League baseball. You know. Yeah, I just want to. I just. There's a lot of games. No, like, I also like every sport because, like, I spend, like, this is this is this is. Still the top five. Just like. It's like it's just there's no point in this. It's like the same thing. Okay? So this was okay.

Whenever I was.

Telling.

That Excel that.

This is all my stuff. No I don't. I think that's. Also I don't know. Yeah, yeah. Wait. How many? Of. Those songs. Oh, I was in the office. Oh. Oh, I don't know, I don't know. Oh my God. But there's no, no, actually. There's one. If. You're going to be. Like you know. You can't, I think. It's probably like. So let's blow things up a bit. Yeah. Oh my goodness. So it was. It was so. I wasn't so much. I just wanted that I have to shuffle. This is all. Um, yes.

Okay. So hi, everybody. And, um. Let's start talking about. Uh, get back to graphs and Dijkstra's algorithm. Um, so last time and in lab, um, you saw, um, some, uh. We saw, um, depth first and breadth first traversals and graphs. Hopefully you have a handle on that. Those were for, um, unweighted graphs. And it turns out that sometimes we like to have, um, we like to be able to find a shortest path in a weighted graph. And of course, that's perfectly normal. It's the way, um, it's the way maps work, right? If you, uh, I can't count the number of delivery vehicles. I, uh, I pass on my way into work every day. It's enormous. Right. So I passed 2 or 3 Amazon trucks and a Fedex truck and everything. Um, they care a lot about this problem now. They care about more than just distance, actually. Interesting fact. Um, I think this was UPS the first time I heard about it, but I'm sure they all do it. They find routes that minimize left turns in countries where you drive on the right side of the road. Because the fuel savings is enormous for the company if they just don't turn left too much. It turns out that these these facts are like really important for a company like EBS or Fedex. Um, now we're going to work on what we're going to talk about waste. The weight can be anything. Right. So the weight can be, uh, some estimate that's based on distance and fuel economy and, you know, all of these other, other things. Um, so this problem, I guess what I'm trying to convey is that this problem is really, really important. People care about it a lot. And if you can come up with a way to do it like ten times faster, you will get great love and vast fortunes from industry. Right? So these things really, really matter. And yet we're talking about, um. Dijkstra's algorithm, which is, um, uh, famous, but it's kind of old. So it's interesting. Right? There's, uh, if you can find there are people have come up with various, uh, new approaches. But Dijkstra's algorithm is still fundamental. And it also illustrates something really useful that algorithms in general. Um, but yeah, so it can be uh, network services can be anything. Um, so unfortunately it's a little bit less dramatic this way. Um, so we're going to learn about, uh, a thing called Dijkstra's algorithm. And it's named for Dijkstra, who's a Dutch computer scientist, though most of his career he was at UT Austin. Um, and he developed this algorithm in 1956. And Dijkstra is a huge, towering figure in CSE, and he's famous for a ton of things. In my concurrency course we talk about, um, semaphores, which were a data structure invented by Dijkstra. Um, he worked he did major, major contributions in operating systems, concurrency programing, language design and implementation, formal verification and proofs of correctness, um, compiler construction, and of course, graph algorithms and all kinds of other algorithms. So really, really heavyweight. He was famous for being like really obnoxious and hard to get along with too. So that's another thing he's famous for. Um, and he's also famous for his handwriting, which is so famous that several people have developed fonts that are based on his handwriting, which you see here, and I encourage you to download it. His handwriting is actually pretty nice. Um, and you have to remember when he came of age, you know, so this was this was the 1950s, but he'd been around for a while, um, at that time, leading intellectuals in various fields would send letters to each other and not just letters like, hi, how are you doing? Like letters like, you know, I think I have a really good way to find the shortest distance in an arbitrary graph. Right. And so he kept track of all these. He, um, he called them e notes, which are his initials, and you would get E hyphen 1302. And I'm not making that up. He had thousands of these. And so UT Austin has put a lot of his writings, both in his own handwriting and also in typeset for, you know, conference papers and stuff. But if you there's a there's a link up there and I encourage you to go, not now, but go at some point and just browse through. And it's interesting because he'll he'll publish a thing that as an end note, that's like why we need to start counting at zero instead of one. That's like that's one of his notes. It is a good paper. It is a good paper. Um, like I said, he was famously obnoxious, but part of what made him obnoxious was he did have a habit of being either right or very well. His opinions were well founded, even if you disagree. And so I encourage you to go and learn more about, uh, um, about Mr. Dijkstra. Um, Professor Dijkstra. So when I was in your seat, one of the most complicated things about this algorithm was remembering how to spell his name. Um, he was also famously picky about stuff like that, about spelling and handwriting. In fact, there's a great story about a student who had an oral final exam with him. And after a short while, apparently, um, Professor Dijkstra said, you know, you know the material, but your handwriting really stinks. Let's work on it. And they spent the rest of the hour like perfecting the kids handwriting. Um, yeah.

So really, really interesting.

Oh. So how do you spell his name? Are you ready? Are you ready? Are you ready, EJC? Once, once. You know IJK are in that order, then alphabetical order. Then everything else falls into place. D. EJC. Straw. There you go. So. Yeah. So I've saved you guys a semester or two of effort learning to spell his name. Um. All right, so, uh, our, uh. Yeah. He's also very quotable. Um, you can read these on your own, but the first one is really, really important to understand. Testing can be used to show the presence of bugs, but not the absence of bugs. And this relates to a statement made by. Oh, no, not Perlis, um, a real heavyweight in software testing. And he he won some award at a conference I was attending. And he gave a great talk on software testing. Um, but one of his things was, Uh, you know, he said, I don't feel happy when my tests aren't producing, aren't finding bugs, he said, because any non-trivial system has bugs in it. So as long as I'm finding bugs, I'm happy because the bugs are there. If I'm not finding bugs, the bugs are still there. My testing is bad. I'm not finding them. Right. So, um, so I think, uh, at this point in your software career, particularly since we emphasize unit testing so much, it's important to understand that the testing can find bugs, but it can't prove that there aren't bugs. It can just, you know, make the bugs more hidden and hopefully less likely to arise. But if you if you want to know that there are no bugs, then you've got to get out your, um, you've got to you've got to write proofs and then you've got to connect your, your program to the proof. And that's not easy. Um, nor is it a subject for CSE 15 just to point out that it exists. Okay. Um, now, it's important to understand that what we did last time was we did find the shortest route in terms of number of hops. But as I hope you've experienced, just walking around and driving and bicycling and transporting yourself in various ways. Um, the number of hops is not the whole story. So, for example, if we want to go from node v2 to v5, there's a very direct route that has only one hop, but it's ten miles long. Maybe it's a road that does like this, or maybe it takes ten minutes because it's a dirt road, right? I grew up in a rural community, so I know something about driving on dirt and sandy roads. And I know that sometimes the dirt road is actually shorter, but it takes longer to use it because you can only drive like six miles an hour if you don't want to break an axle or something. Um, but if you go through v4, this one is a unit. This is three minutes long, maybe, and this is two. So you get there in half the time by taking two hops, going a little bit out of your way, but you can drive fast, for example. Or maybe the graph doesn't show you, but that ten is on a really windy road. That is, that actually is ten miles long. Um, it's one road, but it's it's windy. All right. So with that in mind, we hopefully have some motivation for Dijkstra's algorithm. Why we want it. We care about these problems because they're very important. And what we had before doesn't address the issue. It addresses it only for certain cases but not in general. And we care about those other cases. And so, um, as we start to look at this, Dijkstra's algorithm is, if you understand, after the lab is a great time to do this, because if you understand, um, the BFS algorithm, you're going to understand Dijkstra's algorithm. Um, and just as if you do a breadth first traversal and you calculate the lengths, you find the shortest path from a start vertex to all other vertices. Um, Dijkstra's going to work the same. You're going to you're going to take a start vertex and you're going to find the shortest distance to all the other vertices in the graph that are reachable from that start vertex. Um, and we're also going to start out with the starting node. Vertex has a distance of zero because you're already there. Um, and we'll start out with all the other vertices having a distance of infinity. Because, you know, meaning you don't know how long they are. So we're going to we'll fill those in. Um, we're iteratively going to pick a node whose distance we don't know. And we'll, we'll find a distance for it. And then we'll go through its neighbor. So it, it has all of that structure. Um, the difference is and this comes up in a minute, but it's worth pointing out, is that Dijkstra's algorithm is one of the standard examples of something called a greedy algorithm. So greedy algorithms, this is actually a formal term of art in CSS greedy algorithms and the way a greedy algorithm works is whenever it has a choice, it picks the thing that looks best right now. Based on what I know, it's greedy, right? It doesn't play the long game. It doesn't say, well, I can lose a little money on this transaction, but then down the road, 4 or 5 transactions later, I'll get a big payoff. That's not a greedy algorithm. That's a that's more complicated. A greedy algorithm just says, who's offering the most money. Take it. Right, right.

Um, the.

Interesting thing is often greedy works. And in this case it does, but sometimes it doesn't. And as a computer scientist, if you are exploring things like Dijkstra's algorithm, it can be greedy. Decisions are often easy to make. And so therefore the programing is easy, easier, not easy, but easier. Um, and if you can get out pencil and paper and demonstrate that greedy works, then you win, right? You get to write a simple program and it went, um, if you can show that greedy doesn't win, then you get to decide what to do. Maybe it doesn't win, but it's okay. Or maybe you have to come up with a different narrative. Okay. Uh, so the algorithm is going to start out as before, where we're going to take the starting note. We're going to initialize all the nodes. That step is missing. So step zero is initialize all the vertices. They all have a distance of infinity. And none of them have a known a known shortest path yet. Okay, so everything is unknown. All the distances are infinite. Um, and also the previous node. Same thing. We're going to take that, that that same strategy is going to apply. So nobody has a previous a known previous note yet. Um okay. So then um, um, the distance to the first vertex is zero. Um, so that's known. And we know that the first vertex doesn't have a previous at all. It's never going to. Right. So it has null pointer or some flag that says on the start node, whatever it is. Um, and then what you're going to do is we're going to, we're going to, uh, repeatedly look at all of the unknown nodes, and we'll keep going until all the nodes are known or until we can't get anywhere else. And um, and we'll use a data structure for that, very much like the queue we used for first traversal. Um, and so but here's where we're greedy. We're going to choose the currently unknown node, the one that we don't know the shortest distance for yet. But, um, we're going to pick the one with the smallest distance from this node. Right. So I'm standing at some vertex and it took me 300 hops to get here. And so which vertex am I going to look at next. Um, of my neighbors is I'm going to look at the one that has the shortest distance from here because we're not to get ahead a little bit, but the way you would, I'm not going to do the proof, but the way you would structure the proof is you'd say, well, look, by inductive assumption, I know the shortest distance to this node is n. So if I know that if I pick the neighbor that's closest, then what that means is I've found the shortest distance to that node because I'm the shortest place to be one node away. And that's the right. So well, I found a potential shortest distance. There is a wrinkle that we'll see in a minute. But like I said, I'm not doing the proof. I'm just giving you some intuition about why you should think greedy might be useful. So, um, then once we pick that we do the same sort of expansion we did before, we, we, you know, we, uh, we give it a if we found a shorter distance. So this is a little bit different. Um, if we found a shorter distance to that node, Then we. Then we say okay, it it's shortest distance before was infinity or 900. But I found one that's 330. That's better. So now that that's its that's the best distance seen so far for that node. And the previous node on the path with that distance is me. Right. So we're going to it's similar except instead of doing things kind of unconditionally we're going to check whether we found a better distance or not because it's possible you found a node again. But the previous distance was better. Okay. Um. And then the, um, the node we just explored is now we're going to nail that down. Okay. So let's, uh, let's do an example, I think. All right. Um, I'm going to do this two ways. I'm going to do it one, um, uh, sort of with the smallest amount of screen real estate just to get through the algorithm. And then I'm going to do it the way we do it on the final exam. And and the way you'll do it in lab. So this is the, the the first one. Okay. So arbitrarily we've got a graph we want to find. We want to get someplace and we want to start at v2 because we're at V2 is Boston. And we want to start at Boston. Okay. Um after we go through our initialization procedure, same as before, we've got a distance array or a node array, or maybe they're stored in the vertices. All the choice, all those choices are the same. Um, distances are all initialized to infinity. The start node gets zero, and nobody's known at first. Nobody's short shortest distance is not at first. So little subtlety subtly different from what we did before, but not radically different. Um. Okay, so now we start our loop, right? And what we're going to do is we're going to pick the, um, the unknown node with the smallest distance. Well, that's V2, right? Because everybody else is infinite and V2 is zero. All right. So we pick that one. So we're going to pick V2. And then. We're going to explore from v2. Well v2 has two neighbors v4 and v5. And so what does that mean. Well we found a route from the source to V4 of length zero plus three is three. It was infinity before three is less than infinity. So we will update the best distance to v4 to be three and the best distance to be five to be ten. Okay, I just went through all that in words. So let's look at it in the picture. Okay. So we update the distance. and if there's a previous column, then V2 is the previous, you know. So um, again, um, so far not terribly, uh, different. Um, so we update v4. Then we'll do the same for v5. And then v2 is now known. We've nailed it down. There's not going to be a shorter route to V2. We found it okay. So we're not going to explore V2 anymore right. Nobody okay. All right let's do let's do at least one more. Um yeah. Okay. So now what we're going to do is we're going to go through the table of unknowns. So V2 we don't look at but the, the unknown ones and we'll pick the one with the least distance. Uh, algorithmically, if there's a tie we can just flip a coin, pick one arbitrarily on an exam. I would probably say pick the one with the lowest number, but in this case three has the shortest distance. But sorry, node four has the shortest distance. The distance is three. Okay. So now we're going to pick v4. And we're going to go through our same procedure that we went through before. Um. And um maybe okay. So before we proceed we can say, well this is interesting because in this, in this iteration we're going to mark v4 is known, which means we're going to say we know the shortest distance to it. Well, it was the unknown node with the shortest distance at the time. And so that means that any other node we find. Is that going to make it. Uh, is that going to find a longer one? Well, um. We're not going to find a better. We're not going to find a better route. But there's a wrinkle that we have to. That's worth pointing out. Um, you have to assume that the edges are positive. If the edges are positive, then any future route you find to v4 is going to be longer. But if the edges could be negative, then you could find a shorter one in the future. So Dijkstra's algorithm doesn't work if they're negative weights. It doesn't work. If there are zeros then you get equal ones. And so then which one you pick among equals doesn't matter. But um if they're negative it's just not going to work. And in fact no algorithm will work if there's a negative cycle in the graph. Why is that do you think?

You could just go around and get to negative infinity if you want to get the lowest cost.

Yeah. So I've gone around the loop once and I found the lowest cost so far is negative five. Can I find a shorter one? Yeah. Go around again. If every time around the loop it's negative five then it'll be negative ten. -20. And you can constantly make it shorter. Um, can weights be negative? Sure. If you're modeling financial transactions, you can make or lose money. Right. That's an obvious one. Um, maybe you've got the electricity flowing between two things. It can go in either direction. So one will be considered the positive direction. One will be negative. You can there are lots of things. So um, if there are, if all the edges are positive or non negative then we're going to be set okay. So that's the thing to think about. Um. Okay. So v4 that's what I want to do I want to look at v4. So let's pick v4. and um, that v4 has uh three, six, three, six, seven and five are all, uh, potential neighbors, right? So we have to go through all of its neighbors and update any distance that get smaller. Um, and so we do. Right. So now we know that the shortest distance to v5 is three plus two is five. And the predecessor, of course, is before, um along this route. And we've updated V3 which went from infinity to five. And we updated V6 which went from infinity to 11. And we updated V7 which went from infinity to seven. Right. And then we'll mark, um, it's not in the slide yet, but we will, we will now mark F4 as. No. We're Or not. Okay. Okay. So v4 is. All right. We could go through one more example like that. But I'm going to do the same example with the with the table in a minute. So um I'll just point out that you can arbitrarily pick from Dijkstra's point of view. You can uh. You can break ties. So let's see. So once again, this is an example of a greedy algorithm. Because the way it works is anytime you have a choice, you pick the you pick the choice that looks the best, the lowest weight. In this case, um, when you take 160, you'll hear things about locally optimal. Is it globally optimal? Again, if there are not if there are no negative edges, then Dijkstra's algorithm will work for will be globally optimal as well. And that's what that's what greedy a successful greedy algorithm basically means that local optimal locally optimal means globally optimal. But you can't assume that that's not always true. There's a famous example of this with making change for coins. It depends on what what the denominations are in the currency. And you can pick the denomination so that greedy wins. Or you can pick the denomination so that greedy doesn't win. Uh, no time for that today. But if you want, if you're curious, make a note and you can go have a look at that. That's sort of a fun problem. Um. In 160, you'll learn about something called bellman-ford, um, which is a famous algorithm that sort of addresses this issue. And we talked about negative cycles because there's no such thing as a shortest path. If you have a negative cycle, you want it to be shorter. Go around again. So any any finite thing you can always be by just going around the negative cycle again. All right. So now um, okay. So everybody pay attention. This is important because I'm going to ask you a Dijkstra's algorithm question on the exam. I will have this table. It is a very sad moment when somebody raises their hand in the exam and says, I've never seen this table before. What do I do? It's like. Go back in time and learn it from two weeks ago. I you know, I don't know. So no, it makes me really sad. I really hate that. And it happens every damn semester. Please make it not be this semester, okay? You be the first group that. Well, anyone sitting here is not going to be the problem, right? Um, but we'll get the word out, right? If you know someone who's not sitting here, sit with them and say, let's do this table together, right? Because I want people to show that they know it. Um, why do I use this table? It's the best thing I came I've come up with so far. Actually, a friend of mine came up with it. I stole it from him. Um, the point is, if I just give you the table like we saw before, I don't know the order that you did things. And part of understanding Dijkstra's algorithm is the greediness. You have to understand what order you explore the vertices in. And so this table will show us the first vertex. You explore the second vertex you explore. So it just it makes that explicit. Um okay. So how are we going to use this table. Well let's go through and explain it. Um this is better if I have working slides, but we'll do the best okay. So the first column is the node or vertex number, whatever it is. The second one is the known column which is a boolean value that just do we yet know the shortest distance to this node. The next one is the previous column on the shortest path seen so far to this node. What was the previous vertex? This is so far this is the same as we saw before, right? Right. So knowing this is like we called it visited last time, but you could call it none. Um, doesn't really matter. Um, this is the predecessor on the shortest path so far. So all of these are like BFS, and in fact, the next one is the shortest distance so far. The only difference with BFS is that this column will is the thing that's going to change more than once, right? In BFS it changes only one time because you explore by hops and the hops can't get shorter. By definition. If you've explored all the three hop things, then when you find a four, there's not going to be a three hop thing that would have gotten there because you finished all the three times. Okay, so this one is going to be a bit more dynamic. And that's what these other spaces are for. So, um. We'll go through the example. So what's going to happen here is whenever we explore, whenever we explore a vertex, you put it at the, at the next, the leftmost unused column, and you put that vertex number there. And then you'll update the distances in in the any distances that change will get updated in that column. So you'll prove to me that you know what node got explored next, and what changes got made as a result of that node. Right. So that's that's how we'll do it. There's a little bit of a subtlety, but we'll go through it. Um, and you'll practice this in lab next week. Um, and I said that already. Please, please, please tell other people because I really feel sad about saying, well, I guess, you know, try to figure it out and good luck to you.

Yeah.

I feel like because he is like, I'm pretty sure it's like the current like path that you have current, the shortest path that you have right now would like the life value you get from the B, like the eventual shortest distance you get.

Yes. So the when you get to when you get to the end of the table, all the these are filled in and all of these can be filled in. Because if you have an isolated graph, you'll just you'll explore it and it'll be infinity. But it's still the shortest value so far. And then it won't have any neighbors. And so it stays infinite. So the when you when you get to the last column, the rightmost distance is the shortest distance. Okay. Yeah. Yeah. Um that's it. So your understanding is exactly right. Excellent. All right. So we're going to initialize it the same way. Initially nothing's known. Um, and we'll go ahead and initialize the distances. And you know, the previous of course is no such thing as an empty value. So, um, you know, you can put some however you want to represent this. The zero has no is never going to have a previous note because that's the start. Sorry, one is zero and it will never have a previous. Okay, so once we get the initialization done, um, we start filling in the table and um, the first column will always be the start vertex because that one's going to be zero. Everything else is going to be infinity. Zero will always be less than infinity. And so v1 is going to be all right. So how do we explore that. Well let's see um, we find the uh, neighbors of V1 and we update their distances. If we found a shorter distance so that v2 and v4, since everybody's infinite, um. They're, you know, anything I find is going to be less than infinity. Okay. So we can keep track of sort of the best so far in this column. But then this is when it changed. It changed to two here. It changed to one here. Right. Does anybody understand this.

Can you use one.

Column for every new node your traversing to on your shortest path? Yes. And you fill up every row that you give access for.

So if there's a path to a node then every row will have an entry in it. But if you know, if you have like a node eight that's not connected, then it'll be initialized to false and infinity. It'll stay infinity. It'll eventually become true because your infinity will be the smallest value at some point, because you'll have seen everything else. And so eventually all these will become true. But if you have disconnected elements, it might stay infinity. But there'll be a column for each vertex because you're going to explore every single vertex in the graph. So you take the currently unknown vertex with the lowest value, and you keep doing that until there are no more unknown vertices. So you'll look at every single vertex. So there'll be a column for every vertex question. Um.

Or when you're picking an unknown, uh, like node with the smallest distance to v1. So when you select it and say D4 in this case, um, you're also filling out the information for G2. So are you filling out information for all of the neighbors and then just selecting the shortest distance one to spread out from in the next step? Or how does that work?

No. Well, just if it doesn't change then you don't write anything here. So, like, we didn't, um, we didn't change infinity. So if we, if we found a, um, uh, well, you'll see in a minute, you'll see them. So it'll be easier when we have a concrete. So just, uh, um, just hang on. We'll get there. Okay. Um, so once we've updated all of the neighbors whose distances improved, um, we say, okay, we know that now, V1 is no.

And on on an exam.

Um, I'd like to see, you know, cross the thing out and then put the new thing rather than erase it, because then I only know the last thing, you know. But if I see, um, what we'll see for the previous. Right. Because these are going to, these are going to update and again I get reinforcement, I get okay. Well now they know the correct sequence of previous values. Right. So um just cross it out. Mark f sorry, Martin. Change the F to a T. Um, and then we proceed with the algorithm. So we now look through all the unknown ones. So that's, uh, this one is known, but all these are unknown. So which one has the shortest distance? Well, that would be v4. Okay. Um, so update the distances in the previous, uh, nodes for the neighbors of the for so v4 has so v3, um, we now have. So v4 is best distance right before is best distance is one. So um. Uh, so let's do the left or right. So then V3 will have one plus two is three. We found a route of length three to v3. So v3 that was infinity. So we're going to update that to be three.

And.

V6 was infinity. And we're going to update that to be nine. And um v7 was infinity will update that to be five and v5 was infinity. And we'll update that to be.

I think I've got that.

Everybody okay. Now notice that we I just called out the distances. But any time I noticed a distance that changed we had to update previous. No trouble line through it. All right. Um and then V4 gets known. And so at the minimum again. So let's, uh. Unknown. So one and four are known. Um, so we have two, three, three, nine, five. So this one looks like the lowest one, right? Um v two. So then we write v two in the next column, and then we just keep going like this. Let's, uh, let's work through. Update the distances in the previous for v two. So what? Uh oh I need I scrolled off the top right. Okay. So going to V2. The best distance to v2 we've seen so far is two, right. Um okay. So then we just add two to all of the outgoing arc. So now we've found a thing that goes for v five, um of length 12, and the best we had for V5 before was three. So we're not going to change that. So this is this. This is how we're different from regular research, you know. Right. Okay. Um, and um we found another way to v4. That's two plus three is five. Um, well but four is already known so we don't look at that one. Right. So this is um, so you only look at the neighbors that aren't already, that don't already have a known shortest path. Right. So four was already known. Um, so we don't have to look at that one. Five was, um, wasn't known before, but the previous path was shorter, so we don't update that either. So nothing to update. So the important thing here is now in terms of the table, I know that you've explored V2 and you've observed that nothing changes. So good question. And any.

Question. Yeah.

Just to clarify when we're doing this table out. So when the distance changes do we have to show like how it changed like with the graph. Like do we get to cross out the previous distance if there's a better one then.

So yeah. So for the distance I'll just see the rightmost one wins. So the important thing is that you've seen them change. And we know the rightmost one is always going to be the smallest, because you wouldn't have changed it if it weren't smaller. Um, usually I like to see the previous one crossed out too, because that helps me. Um, I must have forgotten to put that back in the slides.

Um, we just going back a few steps.

Why do we.

Do the v equals four before v equals to like in the columns.

Oh. Because at the time v4 was the unknown vertex with the shortest distance so far. Oh definitely.

Um.

And if you want to be sure you get all of the constraints, you can certainly put that on your reference sheet for the final exam. That's perfectly reasonable. I would probably do that. Um, okay. So now V2 is known even though it didn't really change anything. Okay. So now what do we do? Well, we, um. Well, so these three are known. So what's unknown? This one has a best distance of three. So that's v3. This one has a best distance of three. So we have a tie. Um, nine and seven. Um, we can break the ties arbitrarily, but on the exam, I'll just say take the smallest vertex number, the top link. If there's a tie up at the top right. Okay. Um, so we'll do v3 next. So v3. All right, so who are the neighbors of V3? Where's v3? V3 is two neighbors v1 and v6. V1 is already known, but v6 is not none. Okay, so the shortest distance to v3 was three. So three plus five is eight. So we found a path to v6 of length eight. Hey that's better. So um so we're going to put eight here. And then in the previous we're going to put v3. So now v4 isn't the isn't the previous on the best route V3 is. All right okay I guess I was inconsistent.

Well that sucks.

Um this one's better, but at least this is correct. Everybody okay with V3? So now v3 is known.

Okay.

Um, so once again, we pick among the unknown vertices. By the way, they don't always sort of fall out like among the unknown vertices. Which one has the shortest distance? Well, that would be the five that has a distance of three. Right. So now let's lock it down. Let's explore. Um let's explore v five. So v five has only one neighbor. That's v seven. And um okay. And so the path to v five was of length three three plus six is nine. Um and so we found we found a worse way to get to node seven. So we're not going to change it.

Okay.

And then we have to mark the five is known. And so then let's, uh, let me do it for time. I'm fine. Weirdly fine. Just be going too fast. Okay, so the minimum unknown node now is only node six and seven. Um, seven has the shortest distance, so v seven is the next one. Okay. Of course you know what the last one is going to be. So now let's explore the neighbors at least seven. Um, the the best distance to V7 right now is five. Um, and so um, we found a route to V six of length six now. So the best distance before was eight. So now this is going to become six right. That's the shortest distance to node six. And then the previous node is going to be seven. So we're going to update that.

Get ahead of the slides. I just want to pause here.

So I think this example hits all the significant cases including the one that you're asking about. Right. If you find a if you find a worse thing then you don't write anything down. Um, you know, so you don't write down all the changes. Only all the changes for the better.

Yeah. I was just, uh, I was sort of confused on the basically why in the first case, it was talking about choosing the one with the smallest distance, but then looking at it from, like a perspective of wanting to have something consistent that you can then just loop through that same sort of iterative recursive algorithm or you want to call it, then.

It makes more sense. Okay. All right. Good. So other questions as well. I would love to the best.

Performing question on these. Well.

I love them all. So.

Um, okay, so V7 is now true. And of course, there's only one unknown vertex left. That's six. And in this case it has no neighbors, so there's not much to do. And in fact, since all the other vertices are known, you're not going to look at its neighbors anyway. Add neighbors. Right? So this is kind of the last node is usually not too bad. Okay. Here's what the final table looks like. This is what we would hope to see on an exam. Um.

Yeah. Beautiful. Yes. Uh, just.

To clarify for the previous example, before we had the table, we start from the vertex to and then with the table, we throw with vertex one instead.

Um, yeah. So um, mostly so that we just didn't do the same example. Okay, okay. But uh, but on on, in any instance of a, an application of Dijkstra's algorithm, somebody has to give you a graph and they have to give you a start. Okay. So obviously on the exam I would pick and I'll use my random graph generator um to pick a graph of reasonable complexity. Because, you know, I don't want the table to go off onto your neighbor's paper, for example. Um. That would make my heart. Oh, I was trying to find a better place to do the final exam, but I tried to get the JC downstairs rooms, and I failed. It turns out other people want to have their final exams. Okay.

I don't know. I don't.

Know why.

See, this is.

The most important course of tough.

Specifications. To me.

That's not the way it works. All right. Um, okay, so, uh, if you want to implement each time we select the next vertex, we want the one with the minimum distance. Now, first of all, you can implement it just the way we did. But just think about that for a minute. The unknown the unknown vertex with the lowest thing that's linear in the number of vertices. Right. And you would do that each time. Um, so that's kind of slow. But we have a data structure that's really good at finding minimum values. Yeah we have a couple in fact. But we have one that's very good at this.

What is it a min heap.

A minute yeah. Min heap is perfect. And, um, so we'll use a min heat for that. And now, instead of some loop running times v times size of V, it'll run times log v times log of size v.

Is there a problem with that? Because we're changing like.

The distances in of like the nose.

Yes. There is.

Um, I think so. Uh, the fact that you saw that quickly is really cool, and I'm going to come back to it in a minute. Um, so put a pin in that because, um, that's really interesting.

And I think this may be, you know, but is there nothing because like when we were learning about parity cuz like, I don't think we really consideration.

Should have the highest priority anyway. Sorry.

I don't think we really considering infinity. So does that complicate thing. Like if you can you compare infinity.

Well so you have to have a comparison function. You have to have a way to represent infinity and a comparison function that recognizes that everything else is less than it, than infinity is equal to infinity. So, um, and you guys are familiar with this now with the STL, when you, when you have a map, you have to provide like a a comparison function. And so you can write your own comparison function and you can you can pick a if you're using floating point numbers, you can actually pick a floating point infinity and then less than works. But if you have some you can have a struct that says whether I'm infinite or not. And if I'm not infinite, here's my value. And then you just define your own less than operation.

For this application. It doesn't matter how infinity converges to itself, as long as it is greater than any other number. Right?

I guess that's true. Um, when you're when you have the priority queue, initially everything's going to have a priority of infinity.

Except for one.

Um. Oh, that's true the the first time. You're right. Um, so then zero but you still have to form the you still have to form the, um, the heap. Turns out it's going to be pretty easy, but I think you need to know that it's less than or equal to itself. I think well, you need it to. You need the rat properties. Reflexive, asymmetric and transitive.

Uh.

Okay. So we know that we can get, uh, um, if we use a priority queue instead of taking order v time to figure out which node to explore next, we can do log v, and we have an issue that we may need to think about. The slides actually don't address it, but uh, will they address it by just, uh, by just claiming that it works? Um, so I'm happy to discuss that problem in a minute, because I had an interesting time, um, reminding myself about it yesterday. Uh, okay. So here is the algorithm. Not exactly the code, but it looks pretty much like the code and most languages. So, um, notice that you get a graph and you get a source vertex, um, for each vertex in the graph. Uh, then you're going to set distance and previous to infinity and undefined respectively. Um, the source is going to be uh, get zero as the distance and you're going to create a priority queue. And then you just add every single vertex in the graph. Um, and with its distance as the priority. Everybody okay.

Um.

So order one, order one. This this loop, this loop up to here runs order size of V right times. So that's the size of V plus whatever the final distance okay. But let's just understand what the final loop is doing. Hopefully we've been through the examples so it's reasonably clear. Um as long as your priority queue isn't empty. So there's something in it. Um, you're going to extract min. So this is the unknown vertex with the lowest, um, priority. Then for each neighbor of, uh, of you, um, that is still in queue. Right. So, um, a lot of, uh, algorithms will actually keep a separate visited set, and then they'll ask the question, is this and the visited set, if it's visited and then you throw it away, um, you don't you don't revisit it. Um, okay. For for each neighbor of V still in queue. Um, then find an an alternate distance. This is from Wikipedia. I would just say, um, you know, ker, just I would give that a different name. Um, but anyway, it's the distance to this thing plus the distance to the neighbor. Right? So you've just found a way to get to that neighbor using the distance to me, plus the distance from me to get. So then the next question is, is the alternative better than the distance we've seen there before? And if it is, then you update the distance to the one you just discovered and you update the previous to be this node. Um, and you decrease the priority of V in the priority queue. Now, we did not allow this as an operation before, so, um, if this leaves you feeling queasy, it should. So that's good. Um, and then you do this, and eventually you return the two arrays, the distance and the previous array. Those are the results. Okay. So if we go through this, we've got, uh, you know. Um, order one. We said this loop run size of V times, but of course it's putting things in a priority queue. Each insertion is log v, so that's v v. Um, now we get to the fun part. So as we saw before, um, this inner loop runs in aggregate. After the outer loop has completed all of its runs, it runs order E time. So we've seen that before. So that's not it. Um, this and you're going to have to trust me for at least a minute. Um, we can we can do this in log V time. Right. So that's so that makes this thing be order e log V, right? Right. I think I have that right. And then we've got the first part of the loop that runs v log v times, because you're going to do this for every vertex, and you have to do a log v operation to extract min okay. So it's the sum of those two things. So it's log v times log v plus log e. You just do the you just do the algebra. Um adjacency matrices are worse. So I just don't use it for this. Uh, now let's come back to your question because I found this because honestly, I hadn't taught this for three years. And I looked at it and I said, you know, I remember that this works, but I don't remember how. And I thought, okay, well, if I were going to program it, what would I do? And so I came up with something and then I said, but surely that can't be the way it works. There must be some like deep, cool thing that you can do. And it turns out the deep, cool thing is you change from a priority queue to a different binary heap to a different kind of thing. You use a Fibonacci heap, or you can use something called a leftist tree, which is not a political statement. And then it's just, you know, trees have a left and the right, right. So, uh, uh, but if you stick with a binary heap, um, you'll find a lot of people propose answers and they sort of gently gloss over an interesting problem, which is how do you can you find a vertex in that array that we're using for the heap? Can you find that in constant time? And a priori no. Right. It's going to be order size of heap to find to find out if a vertex is in there. So the thing that I discovered that I did that I thought of that is kind of messy and ugly is okay. So then you keep like a hash table which maps vertices to their current index in the heap. And then whenever you swap things, you got to update the hash hashtag right. So now the swap becomes complicated. But you can absolutely do that. And assuming the hash table gives you constant time access, you're just adding constant time stuff to all the swap, but you're adding it to every swap. So this is like not I don't do this lightly, but as an algorithm, this you can say, well, but it's just constantly and so so you can do that. And then once you find it and you update its priority, now what you have to do is you have to bubble it up. But that's log that, that's log log v. So that's, so that's, so that's my implementation. And I did find 2 or 3 people on the web who did the same thing. So that makes me feel better. And I found a lot of people who just said, uh yeah, it's log N and didn't say what to do. And then other people just punted and said, you know, Fibonacci heaps work really great.

Why do you need to modify the party or something?

Because you've, you've you've added the vertices to the priority queue. And then you're going to update their you're going to update their. So what we did in this algorithm, we put them all in the priority queue first. So they're all there. And then we found well it turns out it's not infinite. In fact we found a distance of length nine.

Why can't you just add a new one to the priority queue.

That's another solution. So what I've done in the past when I didn't do this one is what I did was I added it again to the queue. And of course if you add it to the queue multiple times, the shortest one is always going to be the one that comes out first. But now the heat gets bigger, right? Because the heat grows to the number of things. Added to the heap is order E now, which is okay, but that's just it. So there's a separate analysis for that. But I've done it. I've done it both ways. And it works. You can you can add it. Then when you extract min you sort of have to say, well wait a minute, is this thing visited or not? And then throw it away. If it's if it's been visited before. And then what happens is when you find the longer distances, you just throw them away when they come up. So that works too. And it doesn't mean it does change things. There's the order size of E thing that happens, but it doesn't. It's otherwise very similar. So so there are two good solutions to this. One is when you find a better distance, just put a copy two copies of the put another copy of V into the heap. Um, and now that he will, will have um order e insertions now um v plus e insertions. Um, and the other solution is you have to keep an auxiliary data structure to allow you to find where something is in the heap in constant time, and then do the log n heap up that we up heap we called it before. Right. So, um. That's how that works. And where are we? Oh, wait. Are we okay? There's there's, Um, well, actually, uh, no. So this is a, uh, this is from one of my previous final exams. So I've given this one on an exam. And, uh, though the slide doesn't contain enough, there has to be seven columns, right? One for each V, and, uh, uh, you can you can practice these things. Okay. Well, anyway, um, we'll do it in lab, but you can also just do it on paper and whiteboards. And I encourage you to do them in groups because they're sort of fun. Um, and I really don't want the table to be the thing that limits you. I want well, I want your understanding not to be a limitation, but but a glorious demonstration of your understanding. That's what I want. Okay, so any questions about this before we, we stop because, uh. We start for next one. Yeah. So we can, uh, you can sort of think about that. Um. you know, it starts out the same way. And then the final here's the answer. Um, so this is the solution to that exam. All right. So, um, what's today? Wednesday. Right. Have a great Wednesday, everybody. And a great weekend. And I will see you on Monday.

What are we doing Monday?

Oh, I think it says final review or something. I'm not going to do that. Well we'll see. I'll try to find something more fun.

Yeah. Oh, are you ready? I'll definitely.

Do radix.

Got it. Oh I think. Yeah I just. That's. Uh. The best answer. If I had to start it every time I asked, which is bad. You know what I mean? We didn't know, but, yes, we, um. Now we, like, travel around town. I think so, too. I don't know. I can't go to Hyde Park. I feel the same way. But there are people who actually do something. It's definitely nastiness. And we do not. Uh, he's not there. You already know what's gonna happen. I'm not. Wait. No.

And a part of it was just kind of like. Oh, well, you know, it's like if you have some sort of, like, a distributor.

Or something, you're.

Talking about how the execution spreads along the graph to supply.

The matrix to.

A vector that has what they're not. And then I'll just spread that too quickly.

See, this is exactly why we changed the the math requirement for CSS from calc two to linear algebra.

Yeah, exactly.

Um.

Because all of these are linear algebra questions.

Oh, absolutely. I was talking to him about it, and it was just kind of like it was like, take the algebra.

I had the final exam in my linear algebra class.

Weighted world. Yeah.

Was he taught by your again? No. Um. I feel like everything.

Is on as if I have an oral or, like something. It's always a European teaching.

I don't think. Um. Professor. Kitchen. Jeff. Kitchen. He was great. He was great. Um, just really interesting. One of these Renaissance people, he moonlighted as part of a professional, as a professional harpsichordist and a group that, like, did European tours during the summer and stuff. And so. And his son. He had two kids. One was severely disabled, unfortunately, but the other one was, um, the youngest violinist ever accepted at the Yale Conservancy Conservatory and was like the youngest first chair. So just this fascinating, fascinating person. But he gave the option. There was a take home half and then either an in class half or at your option, um, an oral exam. And my friend Mike and I chose the oral exam. We were the only two.

What was it like? Was it just, like, the same thing?

But we just we trusted that Professor Kitchen was not going to screw us over. That was that was central to this thing. Because we would not have done it if we didn't trust us. And we were curious what it was going to be like. It was great. I learned more during the final exam than we did in the last few weeks of classes, because he sort of established that we knew basic things. We did a proof of this. You remember how that goes? And then he and then he started in with, I didn't get a chance to cover this in class, but it turns out that there's a that this result extends in an interesting way to the complex numbers. How do you think that would work? And then I'm like, oh, well this, this. And then it's like, oh. And then Mike, do you think you could help your friend Mark out here? And then, you know, we're both like working this thing out. And he waters the plants and.

Just very low key guy.

It's great. It was a great final exam. I can't say that about most of my final exams now, but that one was really.

Uh, as a question about. So for the reordering of the priorities. I don't know if you said this, but I didn't really catch what you're saying, but is it essentially log of the being, like the position where.

It originally is because you.

You essentially create like a new list and then do like an insertion.

Right. And in the worst case, it's sort of new because it might be at the end, but yeah, but but it's not going to be at the end. So you're right. But we still say lucky.

Because it was. Yeah.

I just can't remember. What's the name of that insertion. They've been the one where you, they split it in half and then as well the length of the list, I don't know, I can't remember the name.

Like the binary.

Being binary search.

The insertion.

We didn't study Fibonacci heaps. And in fact, I would need to read up on this because I haven't even looked at them since grad school days.

Oh, isn't it like where you divide like you divide by two? And if it's less than or greater than, then you go to the other one in.

Binary.

Searching for that. That's oh, I.

Guess it's oh, I guess.

It's for moving through the.

Heap. You could.

Not.

Replace this with a balanced binary search tree and then find min and extract. Min is still log n. Yeah that's right. And remove min and and finding an element just log in and removing it is finding and removing an element as well. Again. And reinserting it as well again.

So yeah I guess I was thinking so much like a binary search tree but like on the list I guess. I don't.

Know. Um.

A binary search tree doesn't work very well. A general binary search tree, even a balanced one, doesn't work very well in an array, because the, um. The crucial thing that lets heaps work is that they're complete. So, like, if you, if you, if you map children into, into places, there's only a fixed set of places they can go, they always grow from the left of the array because that corresponds to top to bottom, left to right in the tree. Yeah. So they work by this sort of really cool accent. You can absolutely put a, um, a tree in an array. And in fact, that's how it works because your memory is an array.

Yeah. I just think because it's pointers.

Use the indices in your big array before gigabytes.

Because it's ordered. So like I don't see like why like okay let's say you had because it's ordered. Let's say like 1234I don't know I don't know I can't explain it well but like, like if you were to divide the list in then have and then it's like. Here like the essentially the same way as like a binary or even.

Works like.

A binary search. It's. Yeah.

Yeah. That's what I mean.

Um, well then you could store it in a sorted array. And then, I mean, the truth is Dijkstra initially didn't, didn't, you know, he gave his algorithm, but he didn't say how you could, um, and so you could implement things using, you know, everything's a vector. And if it's a sorted vector, then you could find a position, um, and you can even find the place where it belongs if you have to move it in long time, but then it becomes linear to insert it because you potentially have to move everything over.

Yeah.

That makes sense. Yeah.

Because when you were first explaining it like it was just like, oh, like, oh you just use a priority queue. And then you were like, oh, but then you have to change those values. Oh, that's a little more complicated.

It is. It's a um, no, it's more complicated. And and, you know, I've taught the course before, but it had been three years and I forgot. Yeah, because it was like, wait a minute. And so it wasn't obvious. After a three year hiatus from the course where I sort of sat down and of course I challenged myself, I said, no, don't look it up, let's figure it out. And I figured out the thing with the hash table. And I said, and then I also realized you could just add it again, which changes the analysis. And I thought, well, what do people really do? And then I looked up and found that if you find a good I didn't find any source I would actually recommend. Okay. So most of them either ignored it or they did it and it was I think it was right, but I didn't feel it was super clear. So I didn't find a thing. I could recommend it to you guys, but if you find one.

Was there anything?

Share it and I'll put it on the course calendar.

Was there anything on implementations for a star that were nicer, or just does that have too much extra.

Stuff for a star? Did you go to the the faculty candidate talk? No. Um. There was a there's someone applying for a teaching faculty position, and, um, he did his talk on, uh, Tuesday, and he talked about a story. Huh?

Yeah, I'm familiar with it because, like, prior stuff, um, because of the priors where it's like I did robotics through high school, so a lot of pathfinding stuff there, and then also like stuff with video games and everything. And I'm taking the, like, probabilistic robotics right now. So we talked about it very briefly as sort of like a I assume you notice this on like the second day of class. So that was an interesting experience. Uh, but I guess in terms of that, it was just sort of like it wasn't the initial question I was gonna ask, but it was like, since I figured that's probably a little bit better documented.

It's been even longer since. So I watched the talk, and before that I hadn't.

UNKNOWN
Thought about it.