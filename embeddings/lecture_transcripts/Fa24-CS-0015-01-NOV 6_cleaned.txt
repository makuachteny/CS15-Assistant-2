Project three is out. There's a, um, there's a phase one due on the 12th. So that's, uh, Tuesday, um, six days from now. Um, not too onerous, but, uh, but a thing to do and, uh, that's that. Any questions about sort of, uh, projects and timelines and stuff?

Um, on the project. It's a, there's like, questions with a check off.

But then there's a.

Yes. So good question. There's a post on Piazza about about this, in fact. Um, so you should uh, but that's okay. It's fine to ask. Um, so mostly those questions are for helping you get started. Um, making your making your life on the project more difficult because we didn't make it turn it in as sort of not a good trade off in my, in my view. So you should really think through those questions because they're really designed to help. And um, thinking before programing is really key. And, uh, I think we may have said this at the beginning, but, you know, when you watch on TV and they show what programmers do, you know, how how that is, we all apparently program in front of clear screens so you can see our faces, which are remarkably well lit, um, and well made up, I might add. And then and then and then symbols rain down and and then there's rapid typing. And then suddenly I have the Kidnaper there in Singapore or whatever.

Right.

And, um, that's not the way it works. I think you know this already. Um, C plus plus is a great programing language and a terrible thinking language. So programing without a plan is like, you know, leaving your front door to, to go on a trip to Alaska without Google Maps or any reservations or flights or anything. Right. It's a it's not a good idea. So, um, so whether or not we give you thinking questions, you should. You should. Absolutely. I'm a fan of drawing pictures, right? I draw pictures all the time. So definitely, um, draw pictures, understand your data structures. It's often if you draw an accurate and accurate picture, it's often possible to essentially recode for various algorithms off the picture. Right? If you've got a tree or a linked list, you can circle all the pointer variables and then you know how to get to them, right? If I've got the address of this thing and I want the address of that thing, and there's a right pointer to it But I can say this arrow right arrow value. And you can just read it off the picture if you've drawn the picture. If you haven't drawn the picture, then you're just taking symbols on the, you know, on the page and sort of going, oh gosh, I hope this gets to the value. Um, so anyway, um, a little bit of programing advice. Um, take some time up front. Um, so we don't ask you to turn in the, um, I think, can you confirm we don't we don't ask you to turn it in, right? Yeah. Oh, good. Because I don't want to say all that and then be wrong. That would. That would suck. Okay. Um, so what's the deal today? Hold on. I need to caffeinate the computer. Oh, the Unix tips of the day. I forgot I was going to do something. Oh, well, not today, I forgot. Um, so we're going to start a new section in the course about sorting. Um, there are no data structures here. Really. So the the course is called data structures, but sorting doesn't really involve any interesting data structures, arrays or vectors or array lists. That that that's what they always are. Um, so there's no there's nothing interesting in that. Um, so why is it in the course? Well. Um, sorting is often considered a fundamental algorithm that every working programmer. Well, sorting algorithms plural, there are many um, are things that, uh, every working programmer is supposed to know about. You'll be asked about them in job interviews. They come up that you'll write little sorts if you, uh, you know, if you've got a big one, you should use a built in sorting procedure. But if you don't, you write little ones. I've written dozens of sorting things, so, um, it's it's well worth some investment in learning. Um, sorting, of course, predates modern computer science. It predates electronic computing devices entirely. Um, in fact, some of the earliest automated sorting techniques were developed in the United States for dealing with census data. And so Herman Hollerith came up with a sorting machine, and you may have seen programing punch cards. Have you seen those? In my first course, I programed those, right. That was how I wrote my programs. Um, yeah, I'm old and uh, so that, you know, goes all the way back to the late 19th century and they had machines. You could put cards in them and say, oh, the somebody's name is in columns 12 through 20, and then sort on columns 12 through 20. Right. You could do this right. Um, so people have been very interested in this for, you know, a century, century and a half. And, um, and so it's been very well studied. We studied to death. We know all sorts of interesting things about it. The weird thing is, we occasionally still make progress because you think if you've been studying something for 150 years, you might have it worked out. And we do have some things worked out, but not everything. Um, I was delighted in 2001 when there was a new sorting algorithm called Tim Sort. It was invented by someone named Tim. Um, and, uh, yeah. So it it comes up and if you just sort of look on Wikipedia for sorting algorithms, you can see. So there's a thing called merge sort, but there's not just one of these, there's the regular merge sort cascade merge sort oscillating merge sort poly phase merge sort. But there are all of these sorting algorithms online. And you should absolutely. Um, look at some of them. Today we're going to just look at three in particular. We're going to look at sort of the basic three that most. So here are a bunch of cards with words. And we'll sort them in a second. But the three we're going to look at today are in the spirit of things that if I just gave you things and said here, sort this, you would probably come up with one of these three. They're sort of very intuitive that, um, so what is sorting? Well, you know what sorting is. We've got some notion of order. So we have to be able to compare things. Right. So we have to know this is less than or less than or equal to that or greater. Then we have to compare things um, in that way. Um, in a, in a rat reflexive asymmetric transitive relation. So for those of you in math 61, it's a rat, uh, relation. Um, and so what we're going to do is we've got things in some order, an ordered collection, an array or array list, and we're going to permute them. That means we're going to just change the order. And the result is that we get a non increasing order at the end. Um, now it could be non-decreasing if you're sorting from high to low. But we can just say oh well the definition of less than is greater than. And now now we get okay. So we can play with uh with words there a little bit. Um, so we're going to get all the elements in some non increasing order. And it's non increasing rather than increasing. Because suppose everything in the list has the same value. I suppose just some things have the same value. Right. Then it'll be three three and it doesn't increase from 3 to 3 but it doesn't go to the right. So that's what non-decreasing means. Um, so for, for simple things like integers and strings, we have built in ways to compare those. So that's not normal. Um, for comparing strings though, do be aware that you have to actually look at all the characters. So I mostly will ignore them, but every once in a while that will come up with something you need to pay attention. Um, if you have a class like a person, you might want to sort them. You might want to sort them by birthday, you might want to sort them by class year, for example, for registration, which is coming up next week, you might want to if you've got patients in a hospital, you might want to sort them by the time of their surgery. ID number. Right. Any number of things. Um, obviously if you define a class C plus, plus doesn't know how to less than that class or less than or equal to that class, it doesn't know. Um, but the cool thing is we've seen operator overloading. So if you have a class and you want to compare it, you can actually define a less than operator for it. In fact, you can define you can have multiple ones, but that's another story for another day.

If you, um, have a class.

And you define like the less than operator, you know, like a person based on age, well, C plus plus just kind of figure out that if you do less than or equal to, that's like less than or equal to a or.

You know, I forget.

And I know that I tried this once because I had exactly this question when I first learned about operator overloading. And I think it does not is what I think. Um, so, um, it's a fair question, but you know, how to how to do less than or less than or equal to, and you can even call one from the other. So it turns out not to be too hard, even if it doesn't. So that's a really good question. Um, as we've already intimated, there are tons of applications. We sort stuff by all kinds of things. Now, as we look at our algorithms, there are a few things we want to pay attention to. Obviously, time complexity is very important, right? Um, if you're if you're sorting people, um, according to their registration date, you would like to sort to finish before the first registration date. Right. You don't want to still be sorting in January. We want to, you know, you want to register next week. So time complexity is going to be a big issue. So we're going to put a lot of attention to that. We're also going to think about for each algorithm. And this is this is sort of not really big O here. But um, big O is kind of the worst case scenario or the best of the worst case scenario if you want to make it a little tight. But we're going to consider for each algorithm is there? Are there cases where it might be better than expected? Right. Is there a best case? Um, how bad does it get? We always care about that. And then on average. And what do we mean on average? That means suppose you get a list that's kind of just random. What would you expect to happen. Right. So if you have no information, no apriori information about the data, you kind of plan on the average case complexity. If you know something about the data, then you might have information that would tell you whether it's going to be the worst or the best case. And some of the algorithms doesn't matter because all the cases are the same. So we'll see that. Um, oh, um, this is worth pointing out that, uh, you can prove this, which we tend not to prove things in CSE 15, but you can actually prove that for any comparison based sort, any sort that you do, that's based on comparing the elements, um, the best algorithmic asymptotic complexity and get is n log n. And that's a really interesting and not very intuitive result. And you might be thinking about that qualifier. Um are there non comparison based sorts. And the answer is yes. And it's not on the calendar yet because I somehow dropped it. Meaning the term I'm going to try to wedge it in somehow. It might be the last day of class. I'll get to it somehow. Um, because those are those are fun, actually. And Herman Hollerith. Is the inventor of the punch card. Well, the paper punch card for computing type machinery. Um, okay. So in addition to time complexity, we're also going to be interested in space complexity, which so far we haven't been in the class. Um, we're going to distinguish in particular whether an algorithm is done in place. What does that mean? That means the data is going to be in some array. How much extra storage do we need beyond the array? If it's a constant amount and you know there's going to be some extra storage, probably because at some point you're going to need to say, well, this thing's out of order, let's swap it with some of the other. So you might have a temporary variable where you hold the value while you're swapping. Right. So you might need one extra element storage location. Um, any constant amount of extra space. We're going to call that in place because it's essentially sorted in the array.

In order to access. What's the space complexity? We do like a similar process to time complexity, in which like if we add one time in the algorithm use like n and another times we use less than n, the complexity will be.

Yeah, exactly. And if you used a fixed amount it's constant time. And if it's constant we'll call it in place. Um, the reason it's called in place or not in place, I think Millard calls it out of place, but I which is an interesting so I just, I just set in place or not. It's what I usually say. Um, the classic example is you need a temporary array where you like store stuff while you're working on it, and then you like, copy it back to the original array. Stuff like that. So in a case like that where you have one temporary array, we would say order n extra space. Um, the last thing is we can talk about duplicates. And the term of art here is stability. So a sorting algorithm is stable if two elements that compare equal don't swap positions in the array. Does that make sense. So for example if I've got a list of people and I'm sorting them by birthdays, if I've got two people on the same day, they would compare equal. Right. But maybe I want their order to be the same as it was in the original array. That would be stable. And I do this all the time, um, in spreadsheets. So at the end of the semester, we do all the grading, and then at the end I sort everybody by section and then by last name within the section. And I don't want the sort by last name, so I permute people's sections. Does that make sense? Um, so I want a stable sort for things like for integers. Of course, it's a little hard to tell one three from another three. So that's not it's not a big issue for the foundational types, right. For, for, uh, complicated structs. It absolutely is. Um, and so here we'll, we'll take playing cards. And so the suit and the number are both going to be important. So if we, if we took seven, five, two, five, seven of spades, five of hearts, two of hearts, five in spades, and we sorted them in order based on the face value, it should be two five, five, seven. Right. An increasingly non-decreasing one, um, a stable sort. Because Five of Hearts was first in the original list, it would still be first in the result list that would be stable. If they got swapped, that would be an unstable search, and some algorithms will be stable in some way. And if they won't be, you can sometimes make them stable, which maybe I'll talk about that. So as we go through, um, we'll talk about all three of these things for each algorithm. So I, um, I have here a list of words, not too many one two, three, four, five, six, seven I can't remember, I got them from some dictionary, but they're interesting bar wise, corporeal sore heads. Oh, sorry. Heads is here twice, and I take it out. Maybe I don't care. Sore heads is here twice for ish because it's kind of far, I guess. Extravagant and theosophy. So these are the these are the words. How do I sort it? So here's my original list and say element zero is on top.

You can solve them alphabetically.

I'll sort them alphabetically. Sure. Okay. Can we be a little more? Can we? What's the first step?

Put them in a random order.

Okay, I just did that.

Check if it's the right order.

Oh.

Yes.

Keep doing that. Yes. Okay.

That's a well-known algorithm called bogus sort. And so. Okay. So bogus work. I like that I'd like something that sort of has a promise of convergence in a relatively reasonable amount of time. Yeah.

I would pick one up and then pick the next one up and then depending like I put the first one down and then look at the second one and be like, oh, is this after before?

It's before. Theosophy bar wise was the first one. Theosophy was the second one. So.

And then I keep doing that every time I think of.

Well, so now what do I do with these two? Do I just do I do I like.

No I would leave them like spread out. Am I?

Oh, okay. All right, all right. So we can do that? We can.

Yeah.

Okay.

Okay, so you have the first two. Okay. Look at the third one. Yeah. Yeah. And then with that one, the long after or before those three or in between, like that's what I do.

Okay. So. Well, so we have to be, um, we're going to come to this. So one way to do that is to sort of back up one and say, ah, do you belong after this thing? Uh, no, because corporeal comes before Theosophy. And then we could say, do come before that. Okay. Yeah. So we can absolutely do that. And we could do the same thing with swords, which goes before Theosophy, but not before corporeal. Um, Forrest comes before Theosophy, before sort heads, but not before corporeal. Extravagance comes before Theosophy, before sort heads, before faj, um, but not before corporeal and saw heads. Does that right. So that's one way to do it. Um, that that algorithm has a name. It's called insertions. Okay. Everybody like that algorithm. There are other ways to do it. Um, I would probably do something like this. I would have a temporary or I would have an output list, and I've got my input list and I put Theosophy there and then I'd say sore heads. Where does that go? That goes before Theosophy. And then bar wise where does that go? That goes at the front end. Corporeal. Where does that go? And this is called selection sort. So that's another very common one. I'm sure you've probably done that. Okay. So those are two of the three we're going to look at today. Yes.

It's like binary sort or merge sort or something like that.

Right. Yeah. We're going to do merge sort.

Next time okay.

Which is by the way one of my favorite sorts. So I like to do I like merge sort very much because it's useful. Um I like heap sort because it's, it's wacky. And, um. Well, this is a different animal altogether. Um, but I also like radix sort. So radix sort excites me.

Yeah.

We are actually useful in some cases.

No, no, no.

The way you were talking about it sounded like it is.

No, it's a no. It's kind of a joke so much. Okay. Um, okay, so we're going to look at these three today, and then we're going to look at two more next time. And then there's another two coming maybe. Um so selection sort. Oh yeah. Yeah. We'll figure it out. Uh, okay. So how does selection sort work? That was the second one I showed. So the idea is we're going to have a sorted and an unsorted array, but don't rush to judgment on the in place or not. But logically we'll have a sorted in an unsorted array. Initially the sorted array is empty and the unsorted array list the whole array. Right, because we haven't sorted anything. Um Then we're going to repeat this process. We're going to go through the array and find the smallest element. Where does that belong. The smallest element in there. Belongs in slot zero right. Okay. So we have something in slot zero so we can't throw it away. So what we'll do is we'll just swap it. At that point the first element is is sorted now. So now we find the smallest element starting from slot one from the second element. And that smallest element should go where. It's right here. Yes. Go in slot one. Right. So it's called selection sort because what you do is you sort of go through the, the the output indices. And for each one you select the element that belongs there. And you know which element belongs there because it's the smallest of the so far unsorted elements. So you can just go through the array and find the minimum one. Right. You just look at all of the ones you haven't sorted yet, find the minimum that goes in the next position of the output right. So we're going to do this. You do this over and over and over again. Right. So one thing to notice is that after each swap, the sorted portion of the list gets one bigger because you put one more element in and the unsorted part gets one smaller. This is important because if you have n elements and you do this n times, you'll be done and everything will be sorted. There's an invariant here. This is an example where we would have a loop invariant. What we'll say is after every iteration, all of the elements to the left of some boundary are sorted, and all the elements to the writer are unsorted. And then when you get to the end and the boundary is after the last element in the array, then everything is sorted. Right. So this is a case of where we see a new convergence. Okay. So let's work through an example. Um, and we use that, uh, that vertical red bar to show the partition. Um, so initially the sorted elements are all to the left of the red line, and the unsorted elements are to the right. Right. So kind of slot zero is the first unsorted element. So we'll find the minimum element um in the unsorted array which is one. And then swap it with the first of. Okay. And now that we've done that our sorted list is one bigger the unsorted one smaller. So now we find the minimum element in the unsorted array. That's to the right of the line. And that would be three. And you've written this like in 11. You just go through from whatever the starting index is up until through n minus one. Find the smallest one and that's three. And then that's going to swap with the six. And uh yeah. So let me do that. And then now we have two sorted elements. And then we find the sorted element in the remaining array which is six. So that's sort of cool because we don't have to do any swapping that was already in the right place. Um, then we find the smallest element in the remainder which is nine. So nine to the front 11 stays where it is, 17 is swapped with nine, and we go one more. Um, why not? Let's finish it out. So we find the next smallest element, which is 11. Um, and we're done. And of course, uh, A1 we don't really have to go through the process for the last one because a one element array is always sorted already.

How do you like how does the algorithm know where the elements are supposed to be? Like, say like we put like one for the first and the next one. They get six, right? And they put six. Like what? They put six in the second position or they look for three.

I'm a little bit unsure what you're talking about, but um, maybe it'll clarify. We'll look at the code, so maybe that'll help. Okay. Um, basically we're going to keep track of indices. So you'll have sort of what index am I trying to fill now, which is kind of where the boundaries. Right. And then um, and then from that position to the end of the, of the array. And so we just keep track of the length of the array. So then we know what the end is. And then we need to find the index of the minimum element. And then you swap whatever's at the minimum index, the minimum element index with whatever is in the place where you're trying to put stuff like that.

So I guess I'm trying to ask like, how does it know what the next smallest element would be if there's a.

Well, just so you just you just have a loop that goes through so you, you know that you're trying to fill a slot three. So you write a loop that goes from three until up through n minus one or up to, but not including n, and keep track of the index of the minimum element. Uh, right. So you just go through and you, you're probably used to finding the minimum element. The only trick is you want to find the index of the minimum element, because just knowing it's three doesn't help you swap with it. You have to keep track of where it is in the array. And you can do this with pointers or you can do it with indices. Um, the code I'll show you does it with indices. Um, okay. So first pseudocode and maybe this will also help clarify. Um, so we're going to go from zero up to and including size minus one I guess. Um, so we don't really have to do the size minus one if one doesn't work. Um, and then what we'll do is we'll find the index of the smallest element in the unsorted array. Um, so starting right we're going to go through each I. So this is the loop that says we're going to pick the position where we want the next element to go. Initially it's zero. So we want the smallest element starting at zero and going up through n minus one. And then so we find I mean starting at whatever is going up to the end of the list. And then wherever the image element is we swap that with whatever is at position. We just saw the the animation. Um, okay. Now before I show you any code, um, I want to have a little bit of an aside. And I'm not casting shade on my friends in CSS theory, but the truth is that algorithms people are really mathematicians. They may not have an office in the CS department, but they're really mathematicians. And they have. And their goal is not the same as software engineering. They're not trying to produce code that is robust and maintainable and readable. They're trying to publish papers. And when you improve things and when you publish a paper, you need a few things. You need it to fit in one column of a journal. So one letter variable names, right? Mostly just one letter variable names, subscripts, superscripts, little hat characters, all kinds of crazy stuff. Um, and they, they tend to sort of lump all the code together because what they'll do is they'll have a figure and then they'll have like 10 or 15 pages in their research paper explaining the figure, and they want all the code there so you can analyze it and look at it. And then they want to have their proof and all that sort of easier if they have written what we would regard as very bad code. And from a readability point of view, but it's not expected to be maintained by people 20 years later, it's expected to be understood by people who are reading the paper. Right. So so their goals are a little bit different. So and I'm pointing this out because I'm going to show you one example. But um, when you search on the web for sorting algorithms, what most people do is they go to an algorithms textbook, right class or something. Um, the algorithms course I took as a grad student was from the draft notes that later became that book, by the way, which is the textbook that our course uses. 116 um. So they'll go to the book and then they'll just transcribe it into whatever language. And I, you know, I think use your software engineering muscles to, uh, when you can. And so I'll show you an example. So if you go to Wikipedia and you ask for selection sort ah does this okay so here it is. And notice I j okay length. That's good a length. So at least that's better than I or j or just L which is what it would probably be in the paper. Um, a cursive L. So then it doesn't look like a one. Um, and then, um, you know, fry zero up to but not including length minus one. Remember I said the last thing is going to be sorted out. Anything of size one is already sorted. Um, i++. Uh, and you'll notice that this is actually pretty well common. So here's a loop that, uh, um. Test against elements after I to find the small. It's actually good. So the code is well commented. Um, but I would say that the comments don't make up for the fact that it's kind of it's all it's there's a lot of stuff going on. Um, so I'll show you my code, which now I wrote it. So maybe, maybe I'm wrong and you'll say, oh, this one is easier. I don't know, um, but it doesn't matter whether you like this or not. What's what I want to put on the table is that you take the time to think through an application and organize it yourself. It'll do two things. You'll understand the algorithm better, and hopefully your code will be more maintained. So one of the things that I did was I said, well, you know, if we look at that code, there's this outer loop in the inner loop. The inner loop is finding the index of the minimum element. And because it's written with I, j and k and I, at least they said I'm in often they would just say k. Um. This thing is really has a purpose. It's to find the index of the smallest element. So I said, you know what, let's take that out. We'll give it a name. We call that a function in C plus plus. And so we'll write a function called index of min. And index of min takes an array and a start index and an ending index. And it goes up to but not including the end index. And it returns the end index. It returns the index of the smallest value. It's essentially the same code. I've just pulled it out so that now we can think about finding the index of the min separately. That's a small thing. We can get it right. We can test it separately. We can understand. Um, so initially we presume that the that the first element is the smallest one. Um, and then we'll go from the, the, the from plus one ith element up to but not including two. And just if we find a smaller one we store the index of that thing. It's the same. It's the same loop we had before. Basically I just, I just taken it out and put it in another function and giving the function a name. And then if you do that selection sort is really easy. You go through all of the slots in the array up to but not including size minus one. And for each position I you swap the, the, the, the um, minimum value with whatever's in slot II. You could do this in two lines and you might find that more readable. I might even agree. Um, but if you know that swap array I and j swaps array sub I and array sub j, then this is really straightforward. Okay. So I'm just going to put that out there. Nothing deep about the algorithm. Just as software engineers, we would want to think about how can we improve modularity?

How can we improve readability?

See now. This one doesn't really need very much of a comment, because its name kind of tells you the whole thing. The only thing that's not clear is, you know, you you need to know that it includes from but not to. Okay. Um, and of course, I couldn't resist. So here's a recursive one. Which is this is I didn't change that. I just did this one. Recursive. But the next thing I want to talk about is let's look at the loopy one. And um, which is more conventional and also has better space performance in conventional implementations. Um, not in some implementations, actually. And we'll ask what, how much time does it take?

So how much time does it take.

Well, finding the minimum of a sequence of elements of length n takes longer than time, right? Because you have to. You have to compare each one. You start with the first one. And you, you know, it's not defined for an empty list, but for non-empty list, you just you assume it's the first thing, and then you go through until you find, um, a smaller one. Then that's your new smallest. And you go to. The point is, you have to look at all of the N to find the minimum, right. Everybody okay. And so that's order n in the length of the list. But put a finger on for a minute. Um. Well okay. We'll do it first. Um, so about the first time we do this about N operations, then the next time it's n minus one, because we don't, we don't include the sorted elements. Then it's n minus two, then it's n minus three. Then it's n minus four until you know n minus n minus one. Right. So we go through that um and the swaps will assume a constant time. So the total.

Swap.

Complexity is n times order one, which is ordered down, and the number of comparisons, which is what sorting folks usually count. Um, is that other thing n plus n minus one plus n minus two and so on all the way up through one. And so that turns up to the n times n plus one over two. It's a formula. You can look it up um, which is of course n squared right n squared plus n n squared over two plus n over two. Um so the I'm not going to put the proof on the slides, but the idea of the proof is actually pretty simple. Does anybody know this one.

You know.

Some of the N at the extreme and they wanted the extreme is the same as I mean the one before that and the one before and the one before the simplest one. Yeah.

So what happens is, if you take this thing and you and you break it in half and fold it like that and then add up, so then N gets added to the last thing. So that's n plus one. Um, the thing before one is, is, is going to be um two. Right. So n minus one plus two. That's n plus one n minus two plus three. That's n plus one. So you're going to get you're going to get if it's even you'll get n over two of these. All of them add up to n plus one. And that's where the formula comes.

Nice. What's that.

Okay. Um, if the explanation didn't didn't excite you. Um, just. No, it's ten squared.

Okay. Um.

So let's think about best worst in an average game. So, um, selection sort is what I might call relentlessly n squared.

Yes. Wouldn't it matter if it was even an object?

Uh, yes. And so I'm going to wave my hands frantically about that and just say, that's still before. So, um, uh, so it doesn't matter if it's even or odd. So that's what you're asking, right? The number of.

Terms. Because. Yeah. Because that presumably that's very likely to. Be possible.

Yeah. And that's going to be it. That's going to be at the N plus one point. But it doesn't matter because the proof isn't the proof. I just wanted to give you the proof idea. The proof idea is that you sort of add all these things up and they're all kind of n plus one. So even for the odd case, I'll just punt and say 160 You'll be all right. Um. Great question. Um, okay. So, uh. No matter what you do, you have to keep going through the list. N minus one, n minus two, n minus three. Um, so it doesn't really have a best or worst case. You kind of do the same thing no matter what. So relentlessly n squared space complexity. Um, well, we're using the same array. Right. So it's it's in place except for space. We need overhead to swap elements. And there's even a trick for that which I'll show you in for you. Um, so that's cool. In places is nice. Um, what about duplicates? What do we think? Is it stable or unstable?

Unstable?

Because you can take something that's like the one that goes in it's places way over here. You could pop it over here and now it's way over here.

Right. Good observation. So what happens is, if the minimum is at the back, um, it might, um, you know, you might wind up. So you're going to take this element and then suppose there's another element that's equal to that one. You might wind up swapping it after the first one. Right. And so we can even make up an example uh, here where what happens is we say, okay, um, we're trying the bars here. This is the slot we're trying to fill. So the unsorted array is there. The minimum element is one. Well, now the blue three is after the red three. And it's kind of going to stay here. So it's unstable. When you have an algorithm that's unstable you can sometimes have a trick where what you do is Instead of sorting the numbers, you make an auxiliary data structure somehow that you put the original index in. And then when you have things that compare equally, you can then use the original index as a secondary sorting.

Um.

Selection sort by default is is unstable. And if you want to read more, here are some places. Um, the visualization site I didn't know about. So apparently a student suggested that. That sounds great. Um, I went and looked and it was sort of fun, but you have to navigate, so there's a lot of clicking. But then that it was fun after that. Um, oh, I got to put up a link. There's also on YouTube, there are, there are visualizations of sorting algorithms in the form of folk dances, where each person wears a number. And then when you compare elements, they come out front and dance with each other. And then, like the lesser one goes one way and the grateful. So it's very entertaining. So I encourage you to watch those at some point. I want to do insertion sort next, which is uh, uh, another very common sort. And we're going to have the same idea of sort of divide our array into two pieces, sort of part, unsorted part, and maybe, um, this will become clear, I think, when we look at it actually. Um, okay, so here's the procedure. Uh, we divide the array up just as before. We have the sorted part in the unsorted part. Um, and this time we're going to say the sorted part already contains the first element, because any empty list in any list of one element is already sorted. Right? Just if I'm the only person in the list, then I definitely am. I definitely belong in slot zero because I'm the least element. I'm also the maximum. I'm also the average. Right? When you're the only game in town, you're sorted already. Okay. So we're going to take advantage of that. And then we're going to do what I did with the with the cards, which was, was this? Who gave me this? Yeah. This was your algorithm. Um, what we're going to do is we're going to slide something.

To.

The left until it finds its place within the sorted list. And you already did this, I think, with, uh, um, didn't we have, um, insert in order in the first homeworks? Yeah. So you've already you've already done this. If you have a list that's, uh, that's already sorted, then what you do is you just keep comparing it until you find something larger, and then it goes in front of the larger thing, or you start at the large end and you keep moving it less until you find something less. And then you put it there.

Right.

So we'll we'll work this out. Uh, okay. So we'll do the same thing. And here 11 is already sorted by itself. Now that doesn't mean it's the least elements in the array. That means we have two arrays here. One array just has the element 11 in it. That array is sorted. The other one has six 317 one nine. That's not.

Okay. Um.

So now what we're going to do is we're going to look at the unsorted elements one at a time, and then slide them to the left until they find their home. And their home is either they run into something that's smaller or they get to slot zero and there isn't anything left. Right. So you can your code is going to have to keep track of those two things. You have to keep track of. Um, are there any elements to the left of this? If there aren't, then this is the new element zero. Um, otherwise is the element less? If it is, then it belongs right after that. And if it's, uh, if it's greater than it, then you just you go another step and you do the same calculation. So the six is going to six is less than 11. So it sort of slides over and it gets to slot zero. Now we have two sorted. So now we take three and we sort we do the same thing. Uh It's less than 11, so it slides over one. Now notice a little bit what's going on. You can see that when I compare with 1111 slides over what we're going to do is we're going to swap. So we're going to take these two and say okay is that smaller. If it's smaller then it stays there. If it's if it's larger then we're going to just swap it. And now we compare with the next one in the list. Right. So. They're going to swap. And so three is less than six. And it can't go any further because that's already slot zero. And so it uh lands there. Um then 17 we do the same thing. So 17 we compare it to 11. Hey, it's greater than 11 so it's already in the right place. But now now we know that that slot is sorted. So something has changed, right? The sorted array grew one even though we didn't have to move any one. Oh, no one but one goes all the way to the front. So there are a lot of changes, a lot of, um, swaps. And then where does nine go? Goes there. Okay. Does anybody have the idea. And you could program this. I think so I'll give you um pseudocode. And this is from Wikipedia which gives you more of a mathematics. So this is more what uh, the more mathematical algorithms people would write something like this, they'd say, you know, so I starts at one because slot zero is already sorted. Right. So we're going to start with the unsorted list. And then um, and then so J is going to get AIS. So that means we're going to look from the first um unsorted element. And then while J is greater than zero and um a sub j minus one. So that's the one before the jth position. Um, as if they're out of order, we're going to swap. if they're not out of order? Then we don't swap. So you just. You keep doing this as long as you know. Are you two out of order? Swap. Are you two out of order? Swap. Are you two out of order swap. And we'll keep doing that until we either get to zero or we get to a smaller element.

Okay.

Um, so let me pause for questions. I'm not going to show you see the last question. Yeah.

So insertion sort wandering two arrays.

Um, we so it's in place. So we're so we're ahead of that. It's, we're going to use the same array. We're using the same trick where we use one array. We just mentally or in our code by keeping track of an index we say, well everything to the left of this index is sorted and everything to the right is unsorted.

Is it the same so that.

Um, the same one is selection sort.

The selection sorting only use one array.

Correct?

Yeah. So both of these are going to be in place. And they both have this sort of sorted part and unsorted part philosophy. Um, because the if you view the thing is sets the set of sorted elements and unsorted elements is the same set you started with. Does that make sense? Yeah. Yeah.

Um.

So this is sort of interesting when we think about time complexity. Can you imagine a case where life is easy for this algorithm?

What if everything is already sorted?

Yeah, if it's already sorted, then what happens is you say, well, um, you well, you're already sorted. You. How about you? Are you sorted? Oh, well, you do one comparison, but no swaps because the next thing is lower. Okay, well, how about you? Well, we we slide it back where it belongs, except immediately. The next thing is smaller so it doesn't move. Right. So if it's already sorted, you go through the list once, but you don't do any swaps and you don't have to move anything back. So that's pretty cool because that's order. That's order in. Right? So. And this turns out to be really useful if you're a software engineer and you're collecting data for some reason and, you know, it's mostly sorted already, like if you're sorting things by time but they're sent to you, you know, everybody reports in every minute. What happens is they mostly come up in the same order. Occasionally somebody may be a little late. Right. But they're mostly in order already. If that's true, this is actually a great sorting algorithm. And in fact, most built in sorting algorithms are what we call hybrid. That is, what they do is they use a complicated algorithm until the array gets relatively small, like maybe 20 elements, maybe even 100, and then they'll run something like insertion sort on that, because once the array gets small, then the overhead of more complicated algorithms is often not worth it.

So you know, when you say like almost sorted, is there a way that we can know that, like, you know, because yeah, I see how it's oh, and if it's already sorted, but couldn't it be the case that like, even if, like, you know, a few, you know, like, you know, 5% of the elements are just insert, you know, put in randomly in an otherwise sorted list, like, couldn't that make it all the way to like, you know, n squared or something.

As the proportion increases gets worse and worse? So yes, um, usually, you know, what you might do is you might say, suppose that up to k unsorted elements where k is a constant, right. And um, so the point is you have to know your data. If the data might become randomly jumbled, then you're not going to get order in. But if you know that it's either sorted or they're like 1 or 2 things out of place, it's kind of going to still be ordered, which is pretty cool. Um, but the worst case and you just sort of told me is we go through the elements, so there's n we look at each slots, there's, that's n things. And then for each one we have to slide back. So, um, what causes us to slide back the most.

Of the list is sorted backwards.

Yeah. If it's reverse sorted. Because then everything everything has to go. The, everything has to slide all the way to slot zero. Right. So the first time it slides one slot then two slides. No three slots. Is this sounding familiar? Then for select n minus one plus n minus two plus n minus three. Um but reversed in the other the other way. Um, so, um. Yeah. So this is the same sequence we had before. And the same formula applying is still n squared. So in the worst case it's also n squared. Um we've already addressed that. It's in place. We're using the same array. So that's pretty cool. Um what do you think about stability.

I'd say it would be stable because I guess, like if you encounter a value that's already equal to the value that you're moving, it will just go after that value, which makes it stable.

Exactly.

Right. So as long as you don't do the nutty thing of exchanging two equal things, it will be stable, right? So that's pretty cool. So like if, you know, like our previous example was. In this example, what happens is two is going to go there then um, sorry, three is sorted, then two is going to go here, then these two are going to be equal. So we're critically not going to exchange these. And then one will go. But it leaves these in in order because everybody shifts down. And again you've you've actually programed this in the first homework. So you should have some intuition about it. That's not a complete accident that that's in the first talk. Um okay. Any questions about insertion sort. So they're both n squared. But insertion sort has this sort of cool property that makes it useful in some cases.

Where.

We care about the stability of the sorting algorithm.

Um, so stability is important. If, for example, um, you've already sorted on one piece, but and then you want to sort again on another piece, but you want the first one to stay in place. So the example I gave before was I want to sort everybody by section and then by last name within section. And I don't want when I compare two people at the same name, I don't want, I don't want weird swaps to happen. Right. Or the other way around. I support let's do it the other way around. I sort everybody by last name and then I sort by section. So then that's a better example actually. So then what happens is if there if there are um, you don't want people, um, like Turner shouldn't come ahead of Sheldon just because they happen to have equal section numbers. I want to preserve the original one. So that's a case where that happens a lot. Stability is important. Another example is if you're going to sort but you're doing like a sort based on a priority. But there's a there's sort of a queue. And if two people have an equal priority, you want them to be first come, first served, then you don't want to disturb that order. That would be another example. All right. This last one is, um. I implemented this in my. This was this was an assignment in my very first computing class. We had to do bubble sort. I can't remember if they gave us the algorithm or not. Um, but I implemented it in assembly language because that's what we're using now for the first half of the semester. And, uh, so I have a sort of fondness for bubble sort, but I also have a little bit of, uh, um. What's the word I'm thinking of, uh, post-traumatic stress disorder with it. Um, it, um. It's terrible. Okay. Bubble sort is terrible. Um, it was in 15. We, uh, we we used to have a sorting assignment, which I'd like to resurrect, actually, but students got to pick and and students who did bubble sort, like all of our tests were timing out and it was a disaster. So it took like an extra day to run all the stuff. It was just a nightmare. Um, so, uh, so I'll just put that on the table. Bubble sort kind of stinks. But. So why study it? Because it's a very easy to understand algorithm, right? Um, and it does actually kind of work. So, um, so what we're going to do is we're going to take our list. And we're going to compare adjacent elements. Um, are you to in order okay. Put you in order. Now we compare the next two starting with the second one in that first group. Are you two in order? Actually, yes they are. Um, are you two in order? Oh darn it. Yes you are. How about you two? Aha! You're out of order. How about you two are out? How about you two are out of order? Okay, so you see what I did? I just went through and swapped Adjacent any disordered adjacent elements. Okay. Now, um, why is it called bubble sort? If you do that once, one thing you know is the largest element is now at the end of the array because it sort of lost all of its battles with every other element. Right? So it wound up getting swap swaps. So if it wasn't at the end before, it is now. So you have one sorted element. So now I can go back and do the same thing, but I don't have to look at the last element that sorted. So how about you guys? Are you in order. Um, yes you are you in order? Yes, you. Are you in order? No. You want order now? You want order. No, I don't have to look at you because you're right. And then I do this again. Uh, are you in order? Yes.

Are you an order? No. You want? No, no.

Um. Okay. And you keep doing that. And so eventually the smallest element bubbles to the front. So when you do the algorithm, the way I've just outlined, the smallest element will move probably like one space where they're bored. Maybe. And then the biggest element that winds up at the end. Right. So they bubble into their appropriate places. Um. Okay, so what we're going to do is we're going to have two two pointers. The pointers can be indices in the array. They should be literally like pointer to increasingly they could be indices where they could just be fingers. And so we look at those two. And 11 is greater than six. So we're going to have to swap. And so now we look at 11 and three.

And I can swap again.

And then we look at 11 and 17. And we don't swap it. And then we look at 17 and one we do. And then we look at 17 and nine. And we do swap. And so you can see that 17 which is the largest element wound up in the right place. And Anything that was. And the smaller elements have sort of maybe moved one step closer to their final position. Okay. Then we just do this again. So iteration number two sometimes these are called passes. We'll do pass number two. That one doesn't. That one sticks. But these two change and then these two change. So you can always like shrink. You can move the endpoint back one after each pass because you know that it's already sorted. Um okay. And then we go through the same thing again. One's going to move one place closer. And now that looks sorted to me.

Um.

There's another optimization that you'll frequently see. And um, and that's that, uh, if you keep track of whether you've done any swaps. If you go all the way through the list and you never did any swaps, then that means the list is now sorted. So if somehow that happens before you get through n minus one passes, you can stop early. So that's a good thing, right? Um, that's pretty typical of bubble sort implementations. Uh, okay. So let's look at the pseudocode. And um. Slightly different syntax yet again this is more Pascal. Um so we're going to get n is going to be the length of the array a we'll figure that out somehow maybe gets passed in. We'll keep track of whether we've done any swaps in a particular path. So so in this past we haven't really started, so we haven't done any swaps. And then what we're going to do is, um. We're going to go. So we're going to repeat this thing. Um, as long as we haven't done as long as we've done any swaps. So as long as we have to change anything, we're going to look again and then see if it's sorted. So we're going to have that sort of repeat until format. This is do while if you like your C plus plus um and then we're going to do from one up to N minus one inclusive. Um and then we'll just swap out of order elements. And if you swap any elements then you say okay well I swap it. Um, and so you do that n gets n minus one because now that the last element that sorted. So we don't have to look all the way to the next time swapped gets false. Okay. How do we feel about that. It's pretty intuitive I think. And and if you ask someone to sort, it's kind of a thing they would think of. Just anytime you find something out of order, you put it more in order. Right. So it's a it's a pretty intuitive algorithm. Um, time complexity. Well, in the best case, if you do the optimization where you check for swaps, then it's ordering, because bubble Sort can check whether a list is sorted and any algorithm. So checking whether this is sorted is linear time. You just go through every element and make sure that it's not smaller than the element before it. Right. Does everybody see that. So um is sorted is a is a function you can write it's linear time. And in fact there's a Unix utility called sort that sorts files and stuff. Um but you can do sort dash v which means just don't sort the data but verify that it's sorted. And then if you do that I think it's I can't remember I think the error message, if it's not sorted it says like you know, disorder tells you where the disorder is. Um, I use that all the time. So then you might think that's when you're sorting text to different environments. Um, the particular encoding that's in use, the language encoding can change things. Interesting. Um, okay. So the best case is it's already sorted. You do one pass, you don't do any comparisons, you don't do any swaps. You don't. Of course you do comparisons. You don't do any swaps. Uh, and so you verify that the list is sorted. That's the worst case. Um, order n squared. And it's the same kind of thing that we saw before. Reverse sorted does particularly bad average case n squared. So all of these are sort of worst case and average case n squared. Um, the only one that's really uh the two that are special is bubble sort for already sorted lists. Um, is linear and, um, um, insertion sort. Is it in place? So, um, we can do it in place pretty easily. Um, is it stable? It's hard to tell me, but. So, um. Yes, it is. And I encourage you to sort of think through why that is, but it's sort of similar to what we saw in insertion sort. Is it? It swaps disordered elements. So as long as you never swap two equal things, they'll preserve their original order. So same sort of argument.

Why you said it's terrible, but to me it seems like it's pretty much equivalent to insertion sort and all these things and actually worse than selection sort because it doesn't selection sort doesn't have even in the best case. And it also isn't stable.

Yes.

Well, you're quite right based on the asymptotic analysis, but the constant factors and the cash performance are such that just if you measure it, it's slow. It grows at a similar rate. So whatever, whatever nasty slow time it does for a thousand elements. Um, you know, it does. Um, it'll be 100 times slower for 10,000. So it grows at the same rate. But the the absolute constants are worse. And, um. Um, but this is your observation right here. Um, it looks similar, but but, um, it's, uh, I really don't know of any practical things that use it. It's mostly just used for education. Um.

Um.

I don't know, maybe you can get some intuition by thinking that it does, you know, a lot more redundant comparisons. Um, because, you know, you sort of slide the thing in and then, you know, um, when you, when you slide something in and it's found its home, you don't have to compare the other things. So it tends to work out better, the insertion sort. I don't have a good way to describe the intuition, but I could just tell you, having actually measured it and run several hundred things through an automated thing that checked it at least sizes from zero up to 100,000, that it's objectively worse. I can just tell you that that's or at least it was that year, right? And I never I took it off the table. The assignment after that said you must not use because.

It is just too far out. So are there cases where selection sort would be preferable to insertion despite the like the asymptotics being worse?

Maybe. Maybe I don't have a I don't have good guidance on that because I don't have a good pithy thing. Um, the way these things tend to work in practice is, um, is folks profiling, which you'll study in 40. They actually time them on these. And so you can believe that the built in sorting algorithms have tested this on a huge array of, of data. And so they pick whatever works best on their data. And picking the point where you go to the n squared search. So you'll use an n log n thing, um, to start with. And then when you get down to, you know, it used to be like 20 elements, it's probably bigger now, maybe 100 or even when you get down to a relatively small array, then you go to something like insertion sort. You do some things in it, um, and you can believe they test the heck out.

Um, okay. So, uh.

We can take a little bit of time with this, I guess.

Um.

So this is good, like final exam practice. Um, if you can take a list of numbers, and then you can just run all the algorithms on the list of numbers and see what happens. Uh, and so for this problem, um, remember that we had sort of a notion of a pass. So you do a pass for selection sort. You do a pass, you find the minimum element and insert. That's one pass. Then you find the minimum element. Then you select. That's one pass. Um uh insertion sort. You, you take an element and you slide it left. That's a pass. Then you take the next element. You slide it in bubble sort. You go through the list, exchange disordered elements. That's a pass. So you can sort of write down the list after each pass.

And so.

On. For selection sort we're going to find the smallest element and that will get swapped with 35. So two and 35 gets swapped. Then we want to look for the smallest element to the right of two which is nine. So nine and 42 are going to get swapped I hope then we find the smallest element to the right of this, which looks like 14. So now 14 and see um, yeah 14 and 42 are going to get swapped. Um and so on. So then 16 is in the right place. Um, 35 is in the right place. Um, 42 and 85 are going to switch. Um, 68 is in the right place. 99 and 85. And we're done. So you can sort of go through this. Um, I have slides for them all. Um. So I'll just point out that these are the slides. I encourage you to do it yourself because it gives you some intuition about the algorithms. Um, and we'll stop there, I guess. Any. Yes. Question for.

You. Did you say access to it? Uh, in order to embed. Like when you insert elements the first time, if you didn't.

UNKNOWN
Do it that way, you just want to cover the basic.

Uh, as with all the questions.

The answer is it kind of depends. So you have to you sort of have to think about your application because it can vary a lot, but because insertion can be constant time if you don't worry about the sorting versus linear. But sorting is n log n. So yeah, it's a great question. All right. Have a good day everybody.

I mean I think I think. We all. Know Johnny. When you meet us you know that's cool.

Yeah. So it's.

Like, oh my God, I can't handle stairs at all.

So it's.

Like.

How are you, for example?

So let's suppose we you want a shorter list.

But let's suppose that we want to sort it.

But there's some reason why.

We we we we like.

Part.

Of the ordering.

So like.

Um, everybody with the same priority is in the list in their arrival order. Where they came to the. Store is not a good example. I don't know why you would prioritize them, but, uh, anyway. But suppose we have, um. Well. Oh, I'll give you operating system. So operating systems will schedule the CPU and they'll give higher priority tasks to CPU and lower priority tasks. Can't get the CPU. But if you if you have two things with the same priority, then you kind of want the first one. Who who asked for a CPU. Okay. Right. Does that make sense?

Yes. So if, for example, um, like I'm going to pack up.

Do you want to talk?

Yeah.

Uh, for example. And so we are like, your list is order at the beginning in order of arrival.

Right. Right.

So the there are two things right next to each other, uh, who have equal priority. But one of them got there earlier than the other one. So you don't want to.

Correct?

Okay.

Um, operating systems do do several interesting things about this. So they'll often have like, um, a queue per priority level or something like that. But we're going to talk about priority things. That's coming up. Um, anyway, it doesn't matter for, for sorting purposes. I think you've got the app, if that makes sense. Then I think we're good.

And there's one more thing I want to, um, talk about, like certain sorting algorithms working better for certain Ways of data structure. For example, if you know beforehand that your lists will tend to be sorted. Some algorithms perform better if they're like reverse sorted. Most of the time you want to reverse them. Most of the time, possibly some others would work better because that was like the Kryptonite case for most of our sorting we saw here. Uh, I wanted to know, would it be sensible if you have, like, a huge amount of data? Anyone could, I guess, as to how they behave to, like, survey your data? Yes.

We're not going to talk about that in this class. But yes, sometimes people do what's called pre-processing where they look at the data first.

But some of the data.

Yeah, they may sample it. And we'll actually we'll get to an example where, where a little bit of sampling makes sense. I won't show you the code, but we'll talk about how it gets used to that. So that'll be next. We'll talk about an example like that. So the answer is yes. Um sometimes doing a pass over the data, Even a linear pass can sometimes be valuable. So you can keep a certain amount of statistics, and then you can use that to drive an algorithmic choice. So absolutely.

And also you said that systems that swap algorithms depending on what they encounter, uh, do they swap it mainly on like the size of this or um, these considerations.

Well, for most of the hybrid ones, like if you call the, uh, the built in Q sort function, it's mostly the size of the list. It runs an algorithm. But, uh, they do other complicated things, and I'm sorry, I'm not 100% sure what else? I know they at least do that when they get down to a sufficiently small size. Then they use one of the simple ones that is generally n squared. But but it's not in anyone, right. It gets down to the size of like 20. But but 20 is constant. And 20 squared is 400 right.

So it's a constant. Yeah.

So they absolutely do that. So, um, and I'm not sure what other things they do other than sometimes they do statistical sampling. I mean, when you really care about sorting, they go nice. They do all kinds of stuff. Okay. And then we have a couple questions.

I just had a really quick question. I'm interested in applying to the ACA for sure. Wonderful. Yes yes for an says but it says time not specified. So I just.

So hopefully by registration it will be specified. Okay. Um uh yeah. So you want to keep talking to that. You can go to the that I have some generic advice about this, but you do kind of need to know what it is. Um, it, it meets like four times during the semester or something. It's not it's not super intensive. Um, but we do insist insist that you do it. Okay. And so if you can't do it, we can't hire you. It's it's kind of like that. So, um. Yeah. I don't know why it's not there yet, So I can ask Megan. She's teaching.