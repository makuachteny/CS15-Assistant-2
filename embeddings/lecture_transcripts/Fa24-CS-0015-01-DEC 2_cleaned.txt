Um, we're back into it. And now we all have lots of energy rested after after overeating and watching football or whatever we did. And we're going to continue to talk about graphs today. We're going to talk about graph traversals. Now the truth is you kind of know graph traversals already. But, um, just to refresh your memory, um, we saw graphs. And remember, graphs aren't like graphing calculators and bar graphs and stuff like that. And CSS graphs are collections of Some vertices. The circles, also known as nodes and those vertices or nodes, can be connected by edges, sometimes called arcs. Um, I guess sometimes called the lines. Um, that graph that you see here is an undirected graph because there's no directionality on the arcs. Um, these two vertices are connected by this arc. Um, and undirected is a little bit misleading because it's kind of bidirectional. So it means that, uh. If we're looking at this vertex, this vertex is a neighbor and we're looking at this vertex, this vertex is in a symmetrical relationship. But of course graphs can be directed in which case you write arrows. And I always think of the example of one way streets. Right? So, um, an undirected graph would be in terms of a map, and B all the streets are two way you can drive in both directions on the street. Um, here is a the arcs are one way. Um, another example of this actually would be um, and this is a problem I've given on finance. And actually it has to do with routing water through a distribution system. And usually the water flows in one direction, right? It comes from a reservoir to your house, and then it comes out of your house, but not in the same time.

UNKNOWN
And goes out at least twice. Um.

So you can have directed or undirected edges. Uh, if we don't say anything, then the arcs are just arts. But in fact, they could be waved. Um, if it's a if if the marks are labeled with a numerical quantity, we call that a weighted graph. And this comes up again all the time in my water flow scenario. It could be meters per second of flow through the pipes. It could be um, kilobits per second of the flow through a through a network connection. It could be miles. Um, it could be, uh, fuel usage, the Aki associated with some sort of miracle. Uh, if we sometimes you'll just have labels. You could put.

UNKNOWN
Strings that would just call that a label for.

Everybody. All right, so this is all with you. But part of the point of view is that they can give you an opportunity to clarify anything you were wondering. Um, okay. So, um, that's the basic space of what a graphic And secondly represented mathematically. The graph G is equal to a pair of two things, b and d as you set of vertices, and e is a set of edges and the edges that can be seen. And. How we represent that in a program will have to represent this information. So the vertex set is usually pretty easy. You could use a set. You can use a vector. You can use any is a hash table. You could use any kind of mechanism devised for keeping track of the vertices. The edges are sort of the more interesting design space. And we looked at two different approaches. Um, I'm trying to remember what's the lab for this one? Did you do the hash table there? Okay. So, uh, so then this lab is going to be, I guess, about about graphs. I just it's funny, I just reviewed the, the, I just saw the to blurb about it yesterday and I have I'm blanking on it. Anyway, um, when you get to the graphs lab, you'll see these design choices in real code, and you'll get a chance to roll up your sleeves and play. So we can use one method of representing the neighbor information, which is also called adjacency information, which vertices are adjacent to which other vertices is to use a matrix, and the rows and columns represent the matrices. That's right, represent the vertices and we arbitrarily picked either the column is the destination, um, and the row is the source, or vice versa. And so um, what negative one in this place means, is that there in this particular representation is that there is not an arc from vertex two to vertex one, there is an arc from vertex two to vertex four, and in particular has a weight of 42. So this is an example of a way to represent a weighted directed graph, where the weights are constrained to be greater than or equal to zero. And we talked about this a few times. Um, this is a really big concept in um, I, I know Richard talks about it in 11. You know, this idea of sentinel values and things like that. I know he does because I asked him last week before the break, um, and we've talked about it a few times here and in 40 since I'm teaching 40 in the spring, and I know it comes up in the first assignment. Um, I just want to emphasize that a sentinel value cannot be something that would also be valid data for whatever you're looking, right? So if you're looking at at heights of people, a negative value would be a great sentinel because there's no one who's -three centimeters tall, right? But if you're looking at forces, forces can usually be positive or negative depending on the directionality. So you can't there's nothing magic about negative one in this scenario. It's just in this scenario we're presuming an application where the weights cannot be negative. And so we can use a negative value as a sensor if you if it's possible you can't have a sentinel because all valid integers might be valid weights or all valid floating point. In which case you now have to have an additional structure. You have to have a struct that has a am I valid field or a parallel matrix that has, you know, boolean values in the result? Let's have a negative, Flutes have. So there are things called Nans which mean which stands for not a number. Um, they also have plus and minus infinity. And, um, if you take 4D in the spring, we will take a deeper dive in floating point representations. Um, so I suppose you could use Nan. Um, usually we, we reserve Nans for erroneous computations, you know, and things that where it's not a like division by zero and stuff like that. But, um, in principle, you're quite right. It would be unusual to have Nan as a legitimate weight. So that would be a reasonable choice in that case. Um, all right. This is great. So we had adjacency matrices. We looked at two flavors. One that was boolean for the unweighted is true or false for the art. And the reason for this is the way the case. And obviously if there are labels and input labels, This, whatever.

UNKNOWN
It is, are. Um.

An alternative to an adjacency matrix. Uh, and we're going to see this today. So I'll just pointed out, um, the adjacency matrix. Um, mostly in most graphs the adjacency matrix will waste a fair amount of space because, uh, if you so if you have any vertices and you connect every vertex to every other, then you have n squared edges. That's a that's a lot. And you can see that we have n squared possible places here. So we have a place to store information about every not every edge in the graph, every possible entity. There's another detail. We're generally not going to worry about graphs with their multiple hearts because.

UNKNOWN
It's not that uh.

So for most Applications. The adjacency matrix is kind of a waste of space because most graphs are what we call sparse. They don't have a lot of it. Um, on the other hand, it's very interesting if you have two vertices looking like this turns into an operation. So pluses and minuses write fast to get each thing. Um, perhaps way more things than you need, but they also have another, um. Property. I'm going to look at, um, in a moment. So, um, let's just, just let that hang with that and instead introduce you to the standard alternative to an adjacency matrix, which is um, adjacency lists. So for every vertex you have a list of nodes. And we usually think of them as linked lists. But you know they can be vectors any, any sequence. In fact, it could be said that there's not a priori in the general theory of graphs any reason to by ordering on the neighbors. They're just babies are yet you could imagine, um, wanting to have a default order. Like, you know, you've got this game, things are living on the grid, and the neighbors might be in the north, south, east, west, and much of the nation that, um, or some other thing. But anyway, so we, um, because we usually think of them as either Linkedlist or ArrayList, we call them adjacency list. Um, and here for each vertex you have the collection of vertices that are its neighbor. So vertex one has of its neighbors vertex two projects three and vertex again ordering.

UNKNOWN
An application you can do if you like. Um.

In this case, we don't waste space storing information about edges that don't exist. If this graph has 123456789 ten 1112 edges in it, then we have 12 things that represent the edges. Not numbers, which is six squared. So 749, not 41. There are 17 places. On the downside, if I want to know if four and six are connected, I might have to search a list. And so it's linear in the number of neighbors that even those words could be proportional to the number of vertices, and those would be connected to every other. Okay. So that's our summary. And I'll pause for questions. Comments. I'd like to be back. It's great. So today we're going to focus on directed, unweighted graphs, the directed that we don't really have to think of as much of a restriction, because you can always model an undirected graph as a directed one, where anytime somebody adds an edge, you have an edge in the other direction. So if someone says, I've got an edge for v1, v2, you go write v1 v2 v2 v1. Okay, so you can always represent an undirected graph with an underlying directed framework. You just whenever anybody adds an edge, you put two ways. Um, the unweighted case we're going to postpone because that's going to be a lot of fun. And we'll ask about it on Wednesday. All of these things are very common topics for job interviews. And the thing we're going to talk about next time is especially loved by interviewers. I'm not sure why, but it's an interesting but, um. This is also kind of interesting. I guess I've got a graph, and I want to know if it could be represented as a tree, because if it could be, I can use a more specific representation. That would be better if I give you a graph in some representation. Can you give me an algorithm and a start vertex? Because remember graphs don't have a root or any or front. There's no place to start. So if I give you a graph data structure and I give you a vertex to start at, can you tell me yes or no? This graph rooted at this node could be a tree. The interviewer would hand you a marker and point you at a whiteboard. Or. This is a, uh, at this point in your graph education, this is a good way to think about what's the difference between a graph and a tree. Instead of thinking about whether it's a tree, how would it not be? Right. So if there are any nodes that you can't get to from this node. You've all heard this, this joke where somebody says, you know, how how do I get to to Elm Street? Oh, you can't get there from here. If there are any nodes, you can't get there from here, right? If there's a start vertex and you can't get somewhere, like if somebody gave you the previous graph route, it is six sixes. No neighbors. So obviously not a right because you wouldn't. So if you can't get to any nodes it's not a tree. So trees have to be. Everything has to be connected and reachable from the root. Right. So that's interesting. That suggests a strategy. How could we just.

UNKNOWN
Check that one.

Start from the very first. All the nodes connected and see if we.


Yeah.

So how do we address this?

Make sure that each node wants only one.

Yes, exactly. And so we'll need either some auxiliary data structure or something. Right. So often the way I've done this is I in my in my list I pass around either a hash table or a binary search tree. That's the list of things I've seen so far. And if somebody asks me to explore something I've seen so before, I finished very quickly and I don't recurse, right? Yeah. So.

Um, in terms of, like, storing the nodes themselves, not the adjacency like you. What if you. And like this graph spaces is not connected. What would you point. You know, how would you store all of those nodes, since, you know, you'd have to keep track of both one and four? Like with graph, even though it's not a tree, because there's a cycle, you know, you could just point to one and then you can get to every other node from there. So like for graph see the where would you how would you store the nodes for themselves.

Well so we have some options. So the question is um, you know do we have any tricks we can play with how we scoring?

UNKNOWN
My answer is yes. Um, I think an.

External data structure track, um, it could be, you know, a hash table that maps vertices to boolean values, and there could be a set, you know, it's in the center. It's not. But we can also store things in the vertices themselves. And we'll see an example. So if we look at this graph a if we start at root note that we start at one as the purported root, then this is a tree. In fact, this is a binary tree. One has two children. Two doesn't have any children. Three has one child, but four has two. So that's pretty logical. If you start at three, then it would not be a tree, because there's no way for three to get one and two. So as I said, in order for the question to be meaningful, they have to give you a place to start. Um, graphically, this is not a tree because it contains a cycle. Okay. So cycles around. And this one is not a tree because there's just no way you're going to hit everything, right. So that one is a tree that these two are not trees no matter where you start. Um, two if you start here, it's not a tree. If you start here, there's a cycle. If you start here, there's a cycle in the history, right? There's a cycle in that where you start. Um, but the, the first one is a tree if you start at this one and not if you start anywhere else. Interesting. Okay. So just to put a little precision on that, I think we've actually covered all the basics. So um, we'll go through it to make sure. Um okay. So if if the graph is empty then it's a valid tree because trees can be anything. Right. So there's that. Um, that's a special case. The non-empty case is the hard one. Um, if there's a non-empty tree then there has to be a single root node, right. Um, and that node can't have a parent. So there can be no other node pointing to that one. So that's already an interesting sort of thing. Um, like you can say, well, is this node anybody else's neighbor? and if it is, then it's not the root. So done. I think that would be a thing to do. All the other nodes have exactly one parent. So that's a that's kind of a thing you could check.

Um.

And that brings us to another name for a tree, which is a connected acyclic graph. Okay. It's a connected directed acyclic graph. I should put that in. It's more fun to say. And it also has a very beautiful tree. Right. So trees have a direct you can't you can't go back. No direct connect. Directly.

Okay. Um.

There's a huge class of problems in computing. And like I said, they come up on exams and interviews all the time where you need to keep track of a place you did. Um, in fact, when I was a grad student and we were, my advisor was revising the equivalent of our 105 the programing Languages course. Our first assignment, um, that we used to give the students was to do are these two type expressions equal? But here's the here's the problem. They were they could be recursive type expressions. And they and the idea was equal. Equal means if you unrolled them infinitely would they match. That was the problem. And of course infinitely is not a thing you can do. Um, and so the trick was to keep track of things that you checked before. Right? That was, that was a well, your program wouldn't terminate if you didn't do that. That was a key correctness condition. So we're going to have to keep track. Uh, vertices we've seen before and there are various techniques for this. I still remember, I enjoyed that. Um, that that problem. Um, then I just kept a list because the example.

UNKNOWN
Would be that. Um, okay.

And we're going to we're going to start at whatever they say the starting vertex is. We're going to traverse the graph, as you said. Um, and then we need a way to mark the vertices as seen somehow, which is what you're sort of interested in. Um, and then um. If during our traversal, we ever see a vertex that we've already seen faults, because that means we've found a cycle, so not a tree okay. So we can then go through the list of vectors that vertices and make sure every single one has been hit if there are any unseen vertices. False. Otherwise, we have not seen a cycle and we've hit every vertex starting at that node. So true. Um, now I'm going to generalize this because, uh, there's this word traverse the graph. And that's the topic. That's our central topic for today is how do we do that. And they're sort of um, you already know, like I said, kind of how you do it except for this wrinkle of cycles. Um, and you'll see that that you've been here before. And the one wrinkle, the one big wrinkle is cycles. That's sort of the one thing. Um, okay. So given a graph, a common question is, is there a path between two vertices? Can I get to Tufts from Tufts to, um. Columbia University? Yes. There is a path, uh, that. If so, what is it? And in fact, there might be many paths. And so we might want to know what's the shortest path now in a, in a weighted graph, which we're going to talk about next time it gets more complicated because there might be you know. It might be that the, uh, that the, the longer number of hops it has, a shorter toe has a lower total weight than the shorter route in terms of hop. So hops and weights can be different. So we're going to deal with weights next time today. Just just hops. Um so I can get from v1 to V7 in one two hops. I could also get there in 123 hops. Two hops would be shorter. Right. Okay. Very. common. So let's phrase it a little bit more precisely. Um, given some graph and the start of v3 and a destination, maybe v4. Um, how do we find the shortest path between those?

UNKNOWN
That's a good.

Idea. You kind of know. What's the key? High level idea. Well, first of all, if I ask you to get from V1 to V1, you're there, okay? I mean, can we all handle that case? All right, so that one's not too hard. Now the next one is. Well. So kind of what we'd like to do It is like a traversal that enumerates the nodes in order of their distance, in terms of hops from the starting points. We have a circle like that. For. US breadth first search. Yes. So the solution with graphs is just the graph version of breadth first search. Because what is breadth first search is it enumerates all of the nodes that are that are one hop away, then all of the nodes that are two hops away, then all of the nodes that are three hops, right. And so you just keep going until you find that you're looking, or you keep going until you've hit all the nodes. Now you know the shortest distance to every node in the group. And so you can keep track of that if, you know, if you frequently go places from Tufts, keeping track of the shortest routes to a variety of places seems like the thing you might want to do. Um, okay, so there you go. Um, so if I want to get from the three to somewhere, I look at all the places I can get to in one. Um, if that doesn't contain the thing I'm looking for, then I see. Well, where are the places I could get to? And two halves. Well, those are the places I could get to from. We used to call them children, but now we'll call them neighbors because there's no hierarchical relationship. But, um, if I can, the neighbors are the places I can get to in one app. One on the neighbors of my neighbors are the places I can get to in two hours. And this suggests a strategy that you have, in fact, seen before. Okay. So let's let's work it out by hand before we, um, get too deep into the algorithm. So let's start at B3. And then we explore all the places we can get to in one hop. Uh, those are those two, uh, where were we trying to get? I think we were trying to get to v4. Is that right? Well, it doesn't matter. We'll just do all of it. So, um, so from V3, we have a one hop route to V1 and these things. Okay. So now what we want to do is find out all the places we can get to from those nodes. Well, v1 that would be V2 and B4 and from v6 that aren't v6. Okay. Um. So we can get two D4 and two hops. Anybody see how this works? It's pretty intuitive. Um, that doesn't mean the code is trivial, but it's, uh. Um. But it's breadth first search. And in fact, you've written the code before, except for the wrinkle that. You have to leave the Hansel and Gretel breadcrumbs. You guys know the story. I think if they leave the breadcrumbs behind it. And then if they come back and they find the breadcrumbs, then they know that they've been here before, and they just.

UNKNOWN
Need to be certain.

Um, okay. These are these are all sort of exam review questions. Um. What's that?

What's the root node?

Um, a so this one we're doing we're back to trees for a second because we're, we're using our tree intuition to, to support our, our graph exploration. Yeah. That is coming out of order in this case. Um. A b c d e f g. Right. That's a reversal of the tree. Um, and we call the level order traversal in trees and graphs. There's not really a notion of levels, so that doesn't quite apply. Um, and if we recall depth first search which we're also going to look at today. So it's worth an hour. Tree intuition helps there as well. The key difference is that breadth first sort of goes y y y and gradually gets deeper depth. First search goes deep before it goes wide. And we saw um, several different uh, uh versions. We saw preorder post order. Anyway, so here's a tree. What are the nodes in? What did I say? In order and in order to list.

UNKNOWN
One of the Whatever it.

Is apricot first. No, no, that would be preorder, right? For sure.

Um.

Questions are great.

Okay. So for the depth so I understand for the breadth first search, like for example in a graph there's cycles like a breadth first search. And you just need to keep track of. Time because you have a thing.

Um, exactly. It works exactly the same. You have to have an external way to keep track of what things you visited before. Um, the the theorists who do algorithms work will often say, well, we'll just we'll we'll color each vertex red when we see it or something. And how how a programmer would do that is they might have a field in each vertex that says, have I been visited yet? And they color it red by saying true in that field and false otherwise. And so the same mechanism actually applies. In both cases. You encounter the cycles in different ways, but you detect the cycle in the same way, if that makes sense.

Because I'm assuming you're doing it. So when you like encounter, you know that you've already seen, you got to recall you have to manually stop.

Yeah. So you just returned from that case without further exploration.

Okay. Yeah. But then like return. Um, I don't know.

Uh, I'm not sure I understand the question now.

Because you're trying to get, like, the ones first, so that actually. No, I guess because I understand that.

Well, yeah. So if you had a graph, what we're going to see in the graph how we do. So we're going to go through that algorithm. But suppose that from E there was a path back to a. Um. When you get here, even in an in-order traversal, you can still leave a breadcrumb and say, I've been to a you guys did this, by the way, in the, in the maze, because a maze is a graph embedded in a 2D array. Um, and so we're going to keep track of the, um, so we'll keep track of I'll show you the algorithm in a minute. Short answer is we're going to keep track of for both breadth first and depth first search. We're going to keep track of where we've been. And then depending on what you're doing in the application, you may pick up breadcrumbs or you may leave them there. Right. You may un visit a node or visit it. Again. Depends a bit like if you're doing game trees, for example, where you know you're doing an AI that's playing chess or go or checkers or something. Um, and there may be multiple ways to get to, um, a similar board. Right. So you may have, you may have a choice about whether you need. You may visit one in one's traversal and then decide, okay, I'm willing to open up the door again and do another traversal through other systems. I want to put that off though. Um, you can take, um, um, game design maybe, if you care about this. Okay. Um, but I don't think we have an answer yet. So do we have an answer to this question, which is much simpler? Oh, okay. Yeah.

Um, the, um, the.

Yeah.

DB um, e and. Okay. And. Perfect. Exactly.

All right. So, um, so hopefully you guys are comfortable with trees. Um, and so, um, the big differences are there's no route. So you have to get a starting point. That's easy. You just add a starting point, which if you're doing the recursive ones you had anyway because you would just start off the root, um, and graphs have cycles and so on and keep track. Um, and the key to this is to have some way of keeping track of the places we've mentioned before. And again, you can be very creative about this. I encourage you to, um, you know, write a little just a simple program to, to do this in a few different ways to get used to it. Um. But if you, if you do a complete breadth first, the word search here is a little bit misleading. If you do a breadth a complete breadth first traversal of a graph at the end of the traversal, you now know the shortest path from wherever you started to every other vertex in the graph that's reachable from that start.

Okay.

So easy enough we can keep, um, we can actually have an auxiliary data structure. That's a, um. Well, it it looks like a 2D array, but really we have, uh, two one dimensional arrays here. Um, this one is a boolean value. For each vertex there's an array of visited nodes. And if I'm at vertex two I haven't visited it yet. Um, and we also have an array of distances. You could put this information in the vertex structs themselves. You could do that. Um, that would be fine. And so the way we're going to start a breadth first search is we're going to start with an initialization task. Right. So we we have these parallel arrays or they're in the vertex. Whatever it is we go through either the vertex list or we go through our arrays so we just initialize them before the algorithm starts. Visited us faults for everybody. And we say that the distance is infinity. And we're back to this problem of whether you have an appropriate representation of infinity. And I'll just I'll just put it out there because I feel like I've already beaten up on that. Okay. So that's the initialization class. Once everything is initialized, then we can say, okay, what was the start vertex again. Yeah okay. Well I'm going to visit that one now. Um, and since it's the start vertex the distance is zero. So I'm just recording that. So it's very common to see node structs. That looks sort of like this. Because then when you traverse the graph you just have the information there. All right. Um, and for breadth first search, we'll do the same thing we did for, uh, for trees. Uh, we won't do it recursively. That would be for depth. First search. We'll do it with, uh, with a queue of pending neighbors. Right. So as you add the neighbors at the end of the list, um, what happens is they get further and further from the start point, right? So that we're going to we are going to search things in order of distance from the starting vertex. Okay. Well we'll see how this works out. But uh, right now um, the current distance which is the distance of this node is zero. And I need to take its neighbors list and add those to my queue. So if you wanted v6 get got added to the queue. Everybody okay? This is so far this is really what you've seen in the, um.

Entries.

All right. So then we're going to go around. And what do we do. Well we take the first element in the queue and we explore that one. Oh wait I didn't did I say that we updated the distances. We updated the distances. So we looked up the neighbors. We know that the distance to my neighbors is the distance to me plus one. Right? Because they got to me and however many steps and it takes one more step to get to my neighbor. So um, the distance to v3 was zero. So the distance to v3 is neighbors are zero plus 1 or 1. And now we've seen those before. We've figured out their distance. All right. So pull the next thing off the queue. And that would be V1. And so what do we do for B1. Um, well, we, uh, we find it's neighbors v2 and v4 and v2 and v4. We're going to say, okay, well, now we've, we figured out that you it was one hop to get to me. So it's two hops to get to my neighbors to and for everybody. Okay. Okay. Then we pull six off. Um, six sadly doesn't have any neighbors. And so that one goes pretty quickly. Um, so then we pull V2 off the queue and now we're going to process v2. We look at its neighbors. Uh, v4 we've seen before. So what's happened now is we found a cycle. But what is this cycle represents in this case, it represents a longer way to get to that node. Well, we don't generally care about longer ways, so we just we're not going to look anymore about that. Right. So if we've already visited it we don't update it again. Does that make sense? All right, so before we sort of leave alone and then Wi-Fi though, that one's new. So we'll mark that true. And we've said we've found a path of length three each of these five. Yes.

Do you keep.

Track of like or I mean, maybe sometimes you don't need to, but if you do, um, how would you keep track of like what nodes you need to go through to get because like, yeah, if you're looking for driving directions, you don't just want to hear, well, you can get there in 20 minutes.

Oh man. You've anticipated a slot a few slides from now. So that's a perfect question. And and we're going to get there. We're going to get there because you're exactly right. Um, if someone says, you know, how do I get to Times Square and you say 183.7 miles? Well, thank you, but how do I get there? Um.

Actually, this is 187. I think.

Um, okay, so I've forgotten where we are. Oh. We did. We processed v2, we visited it, and we in the process, we figured out the the distances to its neighbors. Um, four was already known, so five got added to the list. So now we're ready to take node four off the list. And four is it distance two. So its neighbors will be at distance three. Um, and um so we, we v6 we've seen before. So again we found a longer route to these six. But these seven we've, we figured out and then we just have to go through. And what we'll find is that we can pull five and seven off the queue. But all of their neighbors already have had their, um, distances computed. But when the queue is empty, you definitely can't find anything else. So there you go. Um. There's an observation someone might like to make now. It's one of those read my mind type questions. So suppose there were V8 out here. What would that. What would happen? This will be false, and the distance would still be infinite. Which actually makes a certain amount of sense, doesn't it? You really can't get there from here. Okay.

Perfect. Perfect.

Um.

All right.

Um, okay. So now your question. So we figured out the shortest distance. But we we have a problem. Namely we didn't keep track of the route. Huh. Well, that's a bit sad. Um. Now, there are fun things you can do. You can keep, um. You can keep sort of, uh, um. A whole sequence for each node. But actually, it's suffices to do something very, very simple. We can just take our table here and add another array, another parallel array, or another entry to our, um, vertex struct and just keep track of the predecessor. Because if, if you know what the predecessor was when you found out your distance, then when you if you want to get from, you know, A to B, then you just you run this process, then you find vertex B and you read out the path backwards. The start vertex has no predecessor because that's where we started. And that will be the termination condition. When you read the path out backwards, you keep going until you get to a predecessor of none. And then that was the start vertex. Orange. Then you get to the start. Um, and again we have this issue of sentinel values. What you pick depends on the application. I just wrote none in the table. Um, but you can put anything you like. And then so what happens is we go through the exact same process we just went through. Um, except that we have to update the predecessor, uh, for each node. So what do we do? Well, if we start at v3, then we say, well, um, I can get to v1 with predecessor V3 or v6 with predecessor V3 and I update the distances accordingly. My distance was zero. Their distances are my distance plus one.

Okay.

And then we take. In this case we'll take v1 off the cube v1 distance is one, so its neighbors distances its unvisited neighbors distances will be two and that will be V2 and v4. But now their predecessors along this shortest route is V1. V2 has a distance of two and a predecessor of V1. And then if we go to V1, then its predecessor is V3. And then if we go to v3 it doesn't have a predecessor. So it's v3, v1, v2. That's how you figure out that.

Okay.

So quick question. What's the shortest path from v3 to v7? Do BFS. Okay. Done. So then go to.

Cool.

All right. So can we find some P.T. Barnum memorabilia down there. Uh, so we go to V7 and well, we got to V7 from node four. From v4 we got to v4, from v1, we got to v1 from v3, and we got to be free from nowhere because that was the start right? Okay. Three one. Four. Seven.

Ope.

Small matter of programing. I pause for questions.

May require a whole different thing, but.

I'm curious if you can do it with maybe some minor change. But like, what if you had two different types of nodes? Like if you have like students and classes and like so classes have, you know, a number of students and students have a number of classes. And you want to find like, I don't know, how many steps do you have to go to get to another from student to student?

Oh, this is this is great. So there are different ways to do this. Sometimes there can be different graphs. Sometimes there are lots of ways to so different applications. The design space is infinite right. And the application space is huge. Um, there were semesters when rather than we gave a six degree problem. I take this, the teaching fellows were at a at a to dinner or something, and they were and someone was saying, hey, you're my Ta in 105, but I was your Ta in 15, right? And they were figuring this out and they wanted to know. So their, their version of Six Degrees was, um, you know, what's the distance between two people? And he has been a Ta for relationship. And so I gave this, this so we made that the project for that semester. And we got the data. We went to uh, um, wait, was it Bruce or Helen? I think it was Helen. I can't remember either Bruce or Helen was in charge of the database and we got a dump in the database. And so we had we basically had two data files the who took what, when and who tired, what when, and then the students had to construct a graph from that and then answer questions like and of course, we anonymize the data and we didn't put like grades and stuff in it. So, so we just we got a list of celebrity names. And then we systematically said, um, you know, Max is Angelina Jolie and Erika is Brad Pitt or something. And then we just went through and anonymized the database, which.

Wasn't very fun.

Um, so obviously in a case like that, you have to you sort of have to go from raw data to one or more graph structures, potentially with auxiliary structures, or any application is going to be a bit more complicated. Um, but it's a it's a perfect question.

Right.

Um.

I don't know.

If I have anything to add.

To this slide. So if I know it has to proceed between 2 and 3. For example, five has two preceding ones. So which one would you take now?

Um, we agree that if the distance is the same, then it's arbitrary. And so it just depends on your visitation order, how you got them. Basically in this case it was their order in the in the adjacency list. That, that sort of effectively picked the the order. So it's whichever one you encountered first. Um, if you have other constraints then that makes the problem more complicated. But there's not a systematic way on exams. Very often an easy way to do this is to say whenever you have a choice of two nodes to explore, pick the one with the lower vertex number, which actually you could implement. If you have a vector of of vertices, you could do it that way.

Oh.

Oh yeah. Okay.

Um.

All right. So what you keep track of depends on your application. Um, but if you need a breadth first search or breadth first traversal, for some reason nobody calls them BFT. I don't know why they just say BFS, even when it's a traversal and not really a search. Um, they just name the pattern that I guess. Um, you know, if you care about distance, you keep track of it. Um, if you care about predecessors, you keep track of them. Um, if you're doing a BFS, though, you do have to keep track of where you've been before. So the breadcrumb trail kind of not optional. Everything else is kind of application driven. Are you ready for pseudocode?

To one of those.

Um. Oh, I was just reminded of a wonderful talk. Um, maybe I'll post it somewhere. Um, okay, so we get to start vertex, and then as I said before, we have this initialization phase. So before we really start the BFS, we have to go through and make sure okay, nobody nobody has been visited yet. And the distances are all infinity. Um, and the predecessors are.

All unknown.

Or whatever. We're using the null pointer to represent, um, an unknown predecessor, because this is pretty cool, right? Because if you store the pointer to the vertex, then the reverse path is just you go through the linked list. You just basically have a linked list at the end.

Haha.

Is that cool? It's really quite nice to write. Um. It's very satisfying because you do the complicated part and you get to this thing and you go, oh God, another thing. Hey, wait a minute. It's just delete this traversal. Got it.

Right.

Um, you shouldn't have to reverse it. Okay. Um, so then we initialize everything to be unvisited. No predecessors, infinite distance. If we care, then we're going to need a queue. So we, you know, our to do list, then, um, the start vertex. Okay. We're. This is a visitation. Here we go. Start vertex is visited. And we're going to go ahead and put that on the list. And we would set up its predecessor to null pointer. Except that it was already initialized to null pointer. So there's a line that we've optimized for. All right. So then you're just going to keep going until the queue gets empty. Same as you did for the tree. Exactly the same. Um then the current you're going to dequeue the first thing on the queue. Get that one. That's going to be your current node. Um. And, um, the nodes in the queue are all visited already. So we're, we're following the invariant that we're, we're labeling them visited before we put them on the queue. So that's important. Um, and then for every neighbor in of the current vertex only if n is not visited. So if it's been visited before, we leave it alone. Right. It's already got all the information. But if n is not visited, if N is not visited, um, well it's visited now we're officially visiting it. Um, and now we can set its distance to be, um, current distance plus one. We can set the predecessor to be current, and, um, and then we can enqueue the neighbor so you don't keep putting things on the queue over and over and over again. Wants to be visited. Right. So all of this happens only for non. So everybody sort of understand how it works. I think it's just what we did by hand, and it's surprisingly compact. And the actual code is kind of like this. It's not it's not particularly, um, one once you see, it's not particularly complicated. Um, seeing it as okay, so let's analyze. Well, that's, uh, order V, right. It's order order v. Um, okay. So order number of vertices. Um, this stuff of course is order one because that's just, you know, straight lines, simple code. Nothing. Nothing complicated. Um, now this this one is a little bit complicated to analyze, so I'm kind of going to do it two ways. Now, one way to think about this is to say, okay, well we've got this queue. In the worst case, everything's going to get put on the Q all the vertices. Right? In the worst case. Um, but we don't put them on more than once. And so the worst that can happen is that the while loop could run um, order v times.

UNKNOWN
And that's it.

This next one is a little bit complicated in a way, because this is. So how many times does the body of this loop. Well, it runs the number of neighbors from the vertex. So we don't kind of have a real way to talk about that. I mean, we can we can sort of make up notation. Um, we'll call it e adjacent. Um, that's the adjacent, the edges that two nodes adjacent to this one, there should probably be a subscript of n there. Okay. so we kind of have that.

Uh. Okay.

So let's notice something. Let's notice.

It.

Suppose the first node has two neighbors. Then this will run two times. Suppose the second node has 16 neighbors. That'll run 16 times. Two plus 16 is 18. Then the next node has no neighbors. It's like v6. So the loop will run zero because there are no neighbors.

Okay.

How many times. So over all the iterations of this while loop, how many times does this body run? Well, if you add up the neighbors of all the nodes, what do you get?

It's going to be a maximum of V time.

Um, well, it could be that every vertex is connected to every other vertex. That's It's.

Possible.

But we know we we have a little bit of additional information. So that's useful. That's useful. And it's going to come back in a minute. So don't don't forget that fact. But there's something a little bit more precise we can say about it. What do each of these numbers represent.

Yeah. Um you mentioned that the sorry, I just wanted to understand the like for each neighbor.

Of current that's going to run.

The house.

And then.

The. Well, so it's going to run a different number of times for each vertex. This is why you can't just multiply it out, right? Because it's not true that every vertex is connected to three or n. In the worst case it could be V which you spotted. Right. But we we know something else a little bit about it.

It shouldn't. I was going to say that the the for each neighbor of current is based on the number of connections.

Yes.

In something that's based off of the number of vertices. And so I'm not sure how to Really answer that.

Oh, you're right there. So, um, so this so for each vertex that you take off the cube, this is the number of edges originating from that, that vertex. If you do this for all the vertices you you visit a number. For each, you get the sum of the neighbors of all the things, which is the number of edges in the graph.

Right.

So it's not multiplied out. It's not v times the number of edges. It's it's up to v. And we'll come back to that in a minute. But then the amount of work that's done here is proportional to the total number of edges in the graph. You'll do it piecemeal. You'll look at the the the edges starting at v1 and the edges starting at v2, then the edges. But if you start, if you if you add up the edges starting at V the sub I for all vertices I you get the you get all the edges in the graph. Well, all the edges you can get to from discarding, but worst case all the edges in the graph. So you get this not very attractive thing. The whole algorithm then is order v plus order one to throw away order one plus. It turns out that this while loop actually runs order E times. Well okay. So let me let me stop there. Um, it might run v times plus order e times, not times. Because for each vertex it doesn't do all the edges in the graph. For each vertex it does only the subset of edges originating from this node. So you might think that this loop runs order v plus e. And then that would be v plus one plus v plus e is order v plus e Right.

But I think I just.

Gave away the store, sadly. Um, and that's this. The amount of work done in the while loop is actually proportional to the number of edges in the graph. In worst case, it's the number of edges available from any traversal starting at this node. But let's just say worst case total number of edges. This is not something that's really obvious. Every time I teach this, I struggle with how to explain it. And in fact, I was exchanging email with, uh, one of the 160 instructors to see if they had a better description. Um, they agreed with my analysis, but didn't really offer a best way to explain it. Uh, so, uh, anyway, um, order V plus E is the standard BFS.

Oh.

Okay.

But but Why.

Is this here? Twice? Oh, okay. There was a leftover animation. I don't know why that got left. Okay. Um. But there's a wrinkle. There's an assumption being made that you can enumerate the neighbors of a vertex in time, proportional to the number of neighbors of the vertex. That is, you have an adjacency list. Remember I said that adjacency matrices have a couple problems. You can answer the question in constant time. Is there an arc from A to B but you can't answer in constant time? What are the neighbors of A? And in fact, you have to go through that whole row in the table to find all the neighbors. And that's order.

V.

Oh, no. Oh, no. So, um. So when you use an adjacency matrix like that.

Um.

You have to iterate over that whole row. And so any time it said for each neighbor n of current that was an order V operation, then um, um with an adjacency matrix. So if you have an adjacency matrix, um, when your interviewer is asking you the answer, is it square with the order size of these. So what does this tell me? This tells me if you see a BFS in your future pick adjacency list. That's my that's my suggestion.

Um.

Okay. It's worth noting something. This is the code that we did for trees. This is the code that we just did. And you can see that broadly similar except for there's this initialization phase. But the queue gets started. You enqueue the route. There's just the visited business that's new and so would the distance be or but you could keep distances for a tree right. You can keep how many hops to get here. Yeah.

Assuming you run your you run this graph DFS and then.

Look at all.

The of predecessor pointers. And then you reverse them. They give you the O.

Um there is a there is a minimum spanning tree algorithm that's based on this. And my memory is too vague for me to give you a concrete answer. So maybe is the answer. And, um, that's good, but I don't want to talk about minimum spanning trees and all that stuff. I'm happy if you just know the algorithm. Is there.

Any in this.

Anything in this could like? Because it says for each neighbor and of current, so it's not making a specification for it then has an argument.

Oh.

That's a typo. The if statement got deleted. Why did the estate.

Okay.

Yeah.

Yeah. So it was there before in the previous code.

That would mess up all the predecessor.

Stuff. Okay. So there's a did I mention that copy and paste is evil? Okay. Copy and paste is evil. All right. Uh, and you caught me messing up. Uh.

That's it. Yeah.

No, no, because that's.

No, it's an infinite loss. Yeah. So it's wrong. This is wrong. But the previous one was right, and I might forget. So somebody post on Piazza and remind me, because I don't have time to do it now. And I have a meeting right up until the start of the next class. So if you would post on Piazza, remind me to fix that slide, that would be helpful. Um, uh, I want to wrap up with, uh, depth first search. Um, we can do this pretty quickly because you've already seen it with trees. And the relationship between DFS and DFS is is exactly the same. Um, so that first we go. Um, so instead of doing sort of v1 and then v6, we're going to do v1 and then v2 and v4 and you know we're going to go we're going to go deeper first if we if we choose the rule that will always visit to visit the lower.

Numbered node.

First. Then we will get something like this five is a dead end. So then we backtrack.

Um.

Okay. So depth first search you've seen before you saw it in the maze lab. So you've done a depth first search of a and in fact you even had the visited. Right. The little period was the. That is a breadcrumb. Right. You dropped a breadcrumb. I've been here. Um, it comes up in game trees and all kinds of things, because you don't want to list the distance to any particular board. You want to find a board that gets you to a win or maybe a draw. Um, so the pseudocode is um. Similar. Right. So we're going to keep it. We're going to keep track of listed items. And then we can do it recursively. If we do that then we'll have a helper function. Um and then when someone calls you on a node you visited it. You do whatever visit means. So calculate distances or whatever. And then for each neighbor, if you haven't seen the neighbor before and only if you haven't seen it before, you call yourself rehearsing the same thing you did in the maze. Exactly the same. Um.

That's really it, actually.

Um, time complexity is V plus E again and v be squared if you use the adjacency matrix.

So preference for adjacency lists.

For BFS and DFS. Okay. So um I went through that quickly because you've if you take the algorithms that you had for tree BFS and DFS and we've gone through an incredible detail graph, DFS, then you take the same transform you did to get from DFS to DFS with trees. And you do the same thing with graphs. It's exactly the same transformation. Um, if if that seems fuzzy then this would be a good opportunity to review it. Let's carry it out by hand. So we could do BFS and DFS starting. Where do we say node one. This is an undirected graph which is sort of interesting. And we're going to have that pick the lowest numbered vertex. Um so if we're doing BFS then we've seen one okay. And then we want to we want to go deep from one we can get to 2 or 3. Two is less than three, so we'll go to two next. Um, we queue up two and then we queue up three. We queue them up in order. And so then we'll take two off the, um, off the queue. And from two we can get to six and seven. So we'll queue up six and seven in that way. And. Then we take three off the off the queue. And then where can we get two from. Three. Where's the um well we can only get to two, but we've seen that before, so nothing goes on the queue.

Got three minutes.

Because I think I did that very quickly. Are the questions.

Are there no questions. Because it's boring and easy.

Because it's.

Because it's complicated and you don't know what to do.

So remember, we queue up everything at the next distance. Right. So if we start at node one, we're going to queue up every place you can get to from node one. And we're going to do this order where we put them in vertex number order two three. At this point we visited everything at distance zero and everything at distance one from the starting. So now we want everything at distance two from the starting line. And we don't really have to think. We don't have to code that explicitly because it's going to happen in our queue. We're putting things on in order of distance from the origin. Okay. So now we'll take we'll just take two off the front of the queue and we'll find all the things you can get to in one hop. So that would be everything you could get to in zero, 1 or 2 hops. So you can get to six and 7 in 2 hours. Um, we haven't explored three yet, so that has to come off. And when we when we pull three off, we find that there's nothing else to queue up because we've already found a shorter path to every place you can get to from three.

Um, so this is kind of a question about the complexity.

Um.

We inside that.

While loop, you said that it was an order, like number of, like, items in the in the list of edges for an undirected graph. Would it be two? E because each edge is basically like a two way edge. Yes.

Yes, it would be. Um, but for big O we ignore the constants. So it's still order E, but you're right that it's doubled because and in real life, doubling can matter. So you're right. Exactly. Um, okay, so we take six off the Q, where can we get two and one hop from six we can get to five and eight. Oh. Just five. I'm sorry. Wow. I thought I saw a line to eight, but I guess I hallucinated.

Yeah. Okay. Um.

Take seven off, etc.. Keep going till the queue is empty. All right. I'm going to, um, pass as a as an exercise, practice this, um, enjoy lab this week and then welcome back. And, uh, good luck with not good luck. Good skill sir.

You don't need luck if you have skill. know, I.

Like, just.

Like never hurts.

I like not getting carried. Like. I'm getting. This is like. Oh my. For sure. Like I literally showed up. I was like, okay. He's like, oh no.

He's in our lab, Alex.

Well, are you guys going off this our. I know it's like this. I'm just waiting for you.

Anybody's office hours.

You're welcome. You have to see these things faster. Yeah, yeah. Yeah, yeah. I'm 23. It's a Saturday. I'm not. Yawning, bro. I'm okay actually. Okay. Yeah. I'm okay. Yeah. We're fine. Yeah. So we'll start after. But I do need to sign off, like, you know. Actually, yeah, I should be right. So. Yeah, I'm. Like. No, I said you should probably think before. Actually I did. I didn't do that. Yeah, yeah. Like, we.

Can't just avoid.

Giving.

Did you look at how.

Yeah, I tell you. It's like I. Told them all I did is.

S11
Okay. I should.

Push this.

To the repo. Thank you.

And then I've got to get to my meeting. Uh.

Get. Pull!

Get.

Uh, what was this graph traversal.

And it's p and p f.