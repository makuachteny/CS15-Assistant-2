So when last we spoke, we were talking about binary search tree. I want to continue that discussion today, and we'll finish it. And then we'll be poised for a big event next week. in the trees. Before we get started, though, I do want to encourage you when you post on Piazza to make your post public. Um, if they're generally applicable, um, if you're shy, you can post anonymously. Private doesn't mean I'm shy. Private means I don't want anyone else to see this, and it kind of hurts other people. So this this came up, uh, the other day. I noticed that something like three quarters of the posts in one day were posted privately, and about zero of those were actually private. Um, there were things about, you know, how is this graded or there's this kind of error or what is the speck mean when it says this? And the I don't want to be too specific. So I don't want to add anybody because I know this isn't the intention. But then a couple days later, somebody posted the same question that had come up earlier, and I was going to refer them to the earlier one. And then I realized you couldn't have found that because the other person didn't want you to see it. And that's not cool, right? I mean, if if you want to know how something is graded, we don't have a rule that's, you know, you don't have one rule and you don't have one rule. And right, not to pick on you particular, but, um, we do you know, the grading works the same for everybody now. Now. No one noticed. Um, uh, so just please post publicly because, um, we have a nice, inclusive and supportive community and we all support each other. And I like that feeling. I really like that. And that's why it's good if you can use your name, because then I can, you know, I can feel grateful to Mary for posting this question because I have the same question and they got the answer. I can also feel grateful for, you know, Mysterious Rabbit 619 but it's better if I kind of know who it is. Um, and so please, please, please, if it's a general question, post privately and I know that you post publicly, I know that you might be motivated by a personal thing, right? What do we do for sick? Because I've got the, I don't know, pick a Star Trek example. I've got the rejection flu. Um, okay, maybe you're the only one with the rejection flu, but the policy for sickness is the same for everybody. So you can actually post publicly, what do we do if we're sick? Um, and you may be motivated by your code, but the question might be more general, like, you know, do we have to have the big three? You don't have to like, post your code that doesn't have the big three in it. And the error. You could just ask that question. So I know it can sometimes be tricky. And if you're unsure then you can post privately. You can ask us, but post publicly if you can. And um, then we'll all, I don't know, um, I like the feeling better when we do that. So I think this is going to reappear over there. Good. And I must caffeinate my computer caffeinate. So if you guys haven't figured that out, there's a program called Caffeinate that you can download. And when you run it, it just keeps your computer from going to sleep. It's very nice. All right. Um, so binary search trees. Let's come back to that topic. So first of all, what is the binary search tree invariant.

Uh, the left side will be less than one. The right side is greater than.

So yeah. So very good. Yeah. So, um, things on the, on the left are less things on the right are greater. There's one way to think about it. And um, does that just apply to the root. Does it apply to leaves. Yes it does. Of course that's a degenerate case because there are no things to the left and the right. But it's still it's still true. Does it apply to an arbitrary node in the tree. Yes. So the BST invariant is for every node in the tree. All of the keys in the subtree on the left are less than the key in the node, and all of the keys in the subtree on the right are greater. So that's the binary search tree. Of course, another invariant is that it's a binary tree, but the more interesting one is the the this thing about the smaller left. Larger right. Right. So, um, last time we, uh, we talked a lot about them and we did recursive examples, but we didn't do two key operations. We didn't do insertion and we didn't do removal. Um, they're both tricky. The ones we looked at. But insertion is the easier of the two. Now we're going to do a naive insertion. Um, we'll get to a smarter insertion next week. Um, so I just want to put some examples in, and I love this site. I've been ever since. I don't remember who showed it to me that, uh, um, I really enjoy it. Um, okay, so in this tree, if I put a node containing the key of 50, where will it go? It should become the root, right? So here we go. Excellent. Okay, so now if I insert 100, where should it go? Think about the environment. It should go to the right. Right. So the question no stretch okay. No. Stretching is good.

Looks good.

Um, so I have to actually click in there. Okay. So it's going to go over there. How about if I put in 75. Where is that. Well this is interesting right. If we want the tree to be balanced, we can, uh, we can think about that. But, um, we really, if we're going to put it into this tree, 75 is larger than 50, so it has to go down there somewhere. Um, we get to 100. It's less than 100. So it should go to the left of the node containing 100. But they're not tapered. Right. So you can see the visualization sort of showing. So then 150 is going to go I think we are getting the message.

Okay.

We're thinking through the example. We're going to write the code for this in a minute in a couple of minutes. So just sort of note the patterns and see what we're doing. So the first thing to observe is we're using the BST invariant to find out. One way to do insertion is to search for the thing. And if it's there, it's inserted. And if they're duplicates, you do whatever your duplicate thing is for the application. Um, but if it's not there, you put it in the place. You would have liked to have found it had you done the search.

Uh, could you explain the variant? Because I was under the impression that when you insert 75, like you would take the place of 100.

Ah, okay. So, um, so we're doing a very naive insertion here. We're not trying to keep the tree balanced. And in fact, um, we're we're going to try to keep the tree balanced next week. But for this week, we're just trying to get the darn data into the tree and respect the BST invariant. So what you're thinking of is good. And we're going to figure out how to get something more like that next week. But for right now, we just want to find a place to put this that will satisfy the BST invariant. And more than that, every time we add a node, we're going to add a leaf. So we're not going to place it in the middle anywhere. We'll do that. We'll we'll do a smarter insertion next time. So this is what we would call a naive one. Do we do 150. Oh yeah. So now we should do 25 because That 50s right arm is getting pretty tired now, so we'll put something over there, okay? All right. Um, okay, so you guys tell me, what's a node that what is a key that would go to the left of 25 in this tree? One.

Okay.

So what do what happens if they do? Negative.

You can't input negative.

Uh. That's sad. I don't know if I care or not. So let's go with five just to give me some space, okay.

Um.

How about to the right of 25?

30.

30? Um, okay. 30 would go to the right of 25. Um, how about 60? Why now?

It has to.

Be, right. Because that wouldn't be a B. That wouldn't be a VSD anymore. Right. So 16 would have to go in the right subtree of 50. So I think you said 30 was it. Okay. So let's put 30 in. Yeah. Okay. Um all right. So we're going to see that insertion kind of um followed that pattern. And we're going to explore that. We're going to think about um removal in a minute, but or in a few minutes. But let's just think about a few cases. Let's suppose I want to remove. I'll make a really easy case. First I want to remove 200. That's a really easy one to remove. Now notice we had to look to make sure that it wasn't there. Right. So, um, the computer is not a human that can sort of look at the whole tree at a time at once. It has to sort of search the tree and it finds 200 is not there. And then for our application, we can decide whether that's an error or whether it just succeeds silently and says yep, removed because it wasn't there in the first place. We can decide that later, but mechanically it's very easy because we search for it. It's not there. Nothing to do except for an exception maybe, or whatever. Um, how about if we want to remove 75? Well, that's not too hard either, right? Because it's right there. Um, so let's remove 74. Just think about this for a second. Think about what has to happen. Okay. We found 75 and we removed it. But it's hard to see on the graph. But there was a change that wasn't just we can't just delete the node. Right.

Why not?

The pointer of 100 is still going to be it's not going to be null pointer. So you have to make it null pointer again so that you know there's nothing there and you don't try to dereference it and get a segmentation call.

Yes, yes. So, uh, so it's not enough just to delete the node. You have to update any node that was pointing to that point. Right. So that would mean that the um one hundreds left subtree slot has to get updated. Okay. How about if we remove 100 that's even that's a little bit trickier. Because you can't just delete 100 and update 50 because then 150 goes floating off somewhere. That would be uncool.

Yeah.

So children have to become the parents. Kind of like a like a royal succession, right.

And like, all.

The women should go up one place.

Uh.

Yeah. So the, um. Right. So the princess ascended to the throne instead of because the father has unfortunately met some fate that prevents them. Okay, um, so we need to delete 100. But now 5050 was the the no containing 50 was pointing at this thing, and it thinks it has a left subtree and that node is going to go away. But that node had had some subtree. Everything that that node points to on either side is greater than 50 though, right. So all we've got to do is say, well 50 can just bypass 100 and point to the node containing 150. And then uh, that was another direction. All right. So basically the whole lecture is going to be figuring out all of these things, but we're just kind of working it out. Now the um 25. How about 25. That's a bit trickier still, isn't it. Um.

It.

Doesn't matter which one is you. Well, we, um. We're going to find that there is some choice. So it's not fixed.

To one of 25 nodes, has to take its place, and then the other one comes in with that.

Right. So, uh, one of 25 children will take its place, and then we have to fit the other subtree in somehow. So I just want to let that simmer. Actually we're going to that's going to take us probably 25 minutes to get there. So just let that sink in. And oh should we do it. Let's see what happens. Let's do it. Now you should be able to draw these um, because on an exam you won't have access to the site unless we're Harry Potter world. We could animate the paper. That would be cool, but I don't know how to do that yet. Okay. Um. Yeah. Yeah. Uh. All right. Um, so we already did all these examples. You can replicate them yourself, and there's some more examples coming up. Um, I want to start with insertion, and we're just going to we're going to think about it a little bit more precisely then we're going to approach it. Um, okay. So in an ideal world, this would be the way you were asking what someone in this vicinity was asking about the I think you were asking about when we did the insertion, trying to keep the tree balanced, wasn't it? Yeah. Um, so in an ideal world, that's what we would do. And there is no ideal world. But there's a better world next week. Um, for right now, we're going to, uh, we're going to allow stringy trees, if you like. Um, so it's going to be pretty naive, but we have to maintain the BST invariant. That's not negotiable. We can't insert and then not have a valid BST anymore. So that's critical. And the good news is insertion that certain invariants, once you figure them out, are your friends. Because now they can they give you like they can give you signposts and how to think about things. They can give you a to do list when you're lost for something to do. Um, so let's think about the cases. What is the easiest case for insertion?

Back. An empty.

String. An empty tree, of course. So, uh, an empty tree. Then we make a new node for this. This thing. And it's the root. Okay, so. That's the easiest.

Case.

Um, now, if the tree is not, uh, empty, then what do we do? What did we do? What did our visualization say? I want to insert 75. And there's a root node. And the root node contains 50. What do I do.

Compare 75 to 50. That's lesser or greater. And then choose which side to put it on.

Right. And in fact this sounds like now recursive solution. Because what we want to do is figure out which subtree it belongs in and then insert it into that subtree. Perfect. So that's coming out of codewords.

Here we have. The problem solvers.

Believe me or not um I'm also ignoring duplicates. So another easy case is um, okay, the tree is not empty, but this is the thing you're trying to insert. Oh, you're inserting a duplicate for that key. And then this is application specific. If it's a set then you ignore it because you can't have multiple copies of the thing in the set. But if you're counting something then you would you might increase account. Or if you're keeping track of a bunch of passengers all on the same plane, then you just add this one to the list if they're not already in it, right? You do whatever is is appropriate for the given situation. Duplicates. But I'm going to ignore duplicates here. Um, so we we had done a bunch of examples and I guess we can go back and do these. Um.

So let me go back.

UNKNOWN
Here and then, um.

One Five.

Ways to go.

You can control the speed of the animation at the bottom, actually. There's all sorts of things I encourage you to do in practice, but the way you use this is don't just watch it and enjoy it. Um, but think about, oh, okay, where would this go? And then see if you were right and it'll show you it. It will sketch the process for you. What did I just put in? One five, ten. So put in 15. Are you getting a sense of just how bad the tree can get? All right, so you're saying this is kind of great? Um. Okay. Um, right. So the node values are one, two, five, 510, 15, 20. Could we insert them in an order that would give us a bushy tree? This is kind of a fun thought question.

You would start with the value of the value in the tree that's between all the other ones. So in the middle, yeah.

You picked the middle value or the median I guess. Yeah. So if we pick the median then that's good. And then the next node should probably be the median of the set of things that are less than the median. We just put. Yeah or greater than. Right. So you can work in either order. There's not one way to do it. But but you can do it. And you know, as a faculty member who writes exams, I often do this. I, I build a tree for you guys and then.

Yeah, well, the way you insert the nodes, you could either have like a language, you know, the proper bushy tree. Right?

Correct. Correct. So if we take it all back and I think the median is AC3. I think the median is ten. I think of those values. So if we insert ten and then let's go. Let's go greater. So the number is greater than 10 or 15 2025. So then if I do 20 it'll wind up to the right of that one. Now I could work on the left subtree, but I may as well finish off this one. So now if I do 25.

It'll go there.

And then um, 15 was the other one. So 15 is going to be greater than ten and less than 20. And then I can do the same sort of thing on the other side. Are you noticing that the pattern of insertion here kind of follows the pattern of a binary search on a sorted array? Hence the name. Another justification for binary search tree. Your access is to an array. If you view the array as encoding a tree in a particular style that will study later, you're essentially doing your action nodes in the binary search order. Oh.

That's. Neat.

Okay, that was kind of the point that that was kind of the point of the slide. Actually. I just wanted to get you there. Okay. Um. All right, all right, all right. We can't avoid programing forever. Here we go. Um, so we're going to use a public wrapper function because that's what we do. Uh, to make our life easier, do you have to know, are there other ways to do it? Yes. Are we going to do it this way? Yes, because I haven't put the other ones on slides. Um, okay. So we're calling it unbalanced insert because we're not we're not worried about balancing it. And we're going to make a further simplifying assumption that anytime we put something in, we're going to make a new leaf. And so then the question is, you search the tree to find out where that leaf would belong. And you put it there, right. Updating the appropriate parent pointer variable as you go. Um, so we're going to use this trampoline function. Um, so this would be the public function. And so if a client says I want to insert this key now they would they would also give us a value. But we're going to ignore the values. You can just add value arguments if you like. Um what we're going to do is we're going to update the root to the result of inserting that key into the tree, starting at the root. So the private unbalanced insert is going to take the root of a tree and a key and insert that key into the tree rooted at that given node, and then return the address of the root of the resulting tree. Okay. Is this ever going to change? Why are we assigning to it?

If you're not doing something to balance the tree, then it's not because you're always just going to like, look at it and left it right. So.

Um, all.

Right. So mostly it's not going to change. Right. Because we're always making a leaf. And so we look at the root and the leaf will be below there. So it's mostly not going to change. But will it ever change. Is there one case.

If the tree is empty.

If the tree is empty. Okay. Um, we just figured that out, so let's write the private one. The private unbalanced insert is going to. I just gave you the contract, but I'll say it again. It's going to take the address, um, of the root of a tree and he. And it's going to return the address of the root of the tree of that same tree, but with this key inserted. So that's the contract. And again the contract can be a little bit tricky to work out sometimes, but this contract makes this function really easy to write. Um, okay. Well I think we have some cases. Right. What's the first case?

Tree is empty.

Tree is empty. So what are we going to do if it's empty? Tree.

Uh, we basically create the tree with the key.

And then return the result. Right. So we just make a new node and return the address of. That sounds perfect. That wasn't so bad.

Right.

And I'm assuming that, you know, like, we had our new node function that we're using before we've got one of those. Um, you could use a, you know, a node constructor. And of course, if there were values, the value would get put in there. But this is the key idea. So then the next two cases are um, you know using the invariant. So we either insert right or left. And for I don't know why we tend to do less than first. I don't know why. Um, but think about this for a second. So if we insert to the left. Um, we kind of have to do two things, right? Because we have to return something. Whenever you write a function that has a return type that isn't void, you have to return something. So we have to return something. What are we going to return in that case?

The root of the particular subtree that you're at.

Uh, yes. And so if the left subtree is not empty it's going to be the same thing that's already there. Right? Sorry. No, we've just decided this tree isn't empty, so we're going to return tree. We're going to return treat. Right. Because this is the root of the of the tree we've inserted into. It's going to go left or right. Okay. Um, and then we have to recursively descend and there's another little trick, but maybe I'll just go down okay. So we're going to do an unbalanced, um, insertion on the left because the key is less. So I think that much is probably clear to everyone. Um, but remember that this function returns the address of the root of the tree, um, for the after the insertion. And so since this was going into the left of the tree, we have to update the left. This will work out. For example, if the left subtree were empty then we would make a new node that would be the root. And then we would update the left pointer. Remember we mentioned I mentioned in the slides we have to update the parent pointer. We're updating the parent pointer here. Are there any questions about that?

Yes. Is there a case where.

S11
You wouldn't object?

Um.

S11
It is not mandatory. It is.

Yeah. So. Yeah. So if it's if it's not the empty tree case, then you wouldn't have to update the parent. And there are other ways to program this to sort of avoid unnecessary assignments where you where you say you know, what that value you had, I'd like to update you to contain the same value. Um, so most of the time this is just going to put, you know, tree our left is going to get tree error left. But it's not if tree error left were empty. So that's interesting. On the other hand, apart from maybe being annoyed at the waste of the extra assignment in many cases, um, it's not wrong, right? It's never wrong to say X gets x. That kind.

Of.

Is the wrong thing to do well in the world where you can override the assignment. Operator. Maybe I'm speaking a little hastily there, but for simple values, it's never wrong to do that. Um, okay. And then the right case is similar. And so you can see here that we returned the same address, that we got, the same pointer value we got except for the empty case. So that structure is now. In the way the way the contract is specified. This is what we.

Are going to do.

Okay. Um, so this is great. And now we can. Oh sorry.

S11
I don't quite understand what was happening. If you tried to add a key into the tree that was already entry.

Oh, so we haven't handled duplicates here. And the way that I would do that is I would just have another elsif inserted before this one. That said, if the current key is equal to the key you're inserting, and then what you do kind of depends on the situation, right? You either ignore it or you increment a counter, or you add to a list or any number of things. So I'm just going to be because there's variation that sort of doesn't affect the underlying algorithm. I'm going to ignore it, but you just insert an extra cases when you do. Yeah.

In this implementation the duplicate will just go on the right. Is that correct? Um.

Actually you're right because we don't. Yes. So this particular thing, we put duplicates on the right. But we're assuming that there aren't do this. I think you'll generally want them to be a special case in general. But you could you so you could put them on the right I guess. What does I think that's actually what the visualization side does. If you give it a duplicate I think it goes on the right. I can't remember. I know I've done it before. So let's think about the complexity of this.

Um.

In order to insert, we have to find the right spot in the tree and then create a new node and return a pointer. Well, creating a new node. That's constant time. You know, you allocate stuff and we'll assume that there's not a you know, assigning the values of the node is not proportional to the total number of data in the tree. By the way, did I say this. So n is going to be the total number of items in the tree. Whenever you're doing complexity you have to be clear on what N is. Okay. Um, so that's constant time. Um, step one is this annoying thing where if we had a well-behaved tree, well, it's proportional to the tree height, right? The worst case is proportional to the height of the tree. Now, if the height of the tree is the tree is pushing, the height of the tree is logarithmic in the number of things stored energy. But if if the tree is not nice and bushy, then in worst case it's linear. So we have that, that, you know, that sort of, uh, um, hopeful news and ultimately bad news. We would have to say that insertion for the unbalanced insertion to a binary search tree is still order in, which is a little bit depressing, except that I know what we're going to do next, so I'm not too depressed about it. Um, okay. Any questions about insertion? Because we're about to do removal and that's harder than insertion. So if you would like to put that off, you can ask a question. That insertion actually it's not that bad.

It's not that bad.

So there's there's really just one situation where um. So for removal. Um, I'm not going to write the code because your next homework, you'll you'll be writing the code in the, in the next homework. So, um.

I think so. Uh.

So you'll implement it, but we'll work out all the cases, and so hopefully it won't be too bad. Um, the plumbing is the hard part. My, the first time I wrote this, it was right about 30 lines long, which for me is getting to be pretty. I was feeling pretty guilty. Um, I you can shorten it with helper functions, and you can re-architect it slightly, but it's the point of that observation is it's just more complicated insertion. What did we see? It was like 6 or 7 lines long. Right. So insertion is pretty easy. This one's going to be a bit trickier. Um, my advice to you if you are implementing this is, uh, don't try to implement it all at once. And don't test the most complicated case first. Um, you know what? Make sure that you can remove something that's not in the tree. Start there. Right. So do it bit by bit.

Is it close side by. But what's the average length of the program that you would.

That I oh gosh I, I have no useful data on that.

Because on the one hand I could see you writing really long functions because you're doing really on programs because.

You're doing complicated.

Things. But then I could also see you writing really short ones because you do it more efficiently. I mean.

I don't know if I'm that much more efficient than you are, but maybe a bit. Um, uh, the thing is, I write a disproportionate number of very small utilities and a very small number of things I use, like once and then throw them away. The programs I keep around are probably still not terribly long because, you know, I'm not making, like, a spreadsheet or something. I'm not working at Microsoft. Um, so these days, probably a few thousand lines max, but probably that's rare. That's where it's probably, you know, hundreds, 2000 maybe. I don't know, it's a it's an interesting question and I don't have a good answer. Okay. Um, right. So, um, this this this debugging hint is really key because I think that often, um, students get and I used to feel this way, I don't know where to start. And so I can't do anything because I don't I don't understand everything. But you don't have to understand everything to understand something. And you don't have to understand everything to implement something. And this doesn't just apply for the whole program. It can apply to an individual function. You can write only one case of a function and then and then write throw to do finish writing this function after that. And then you can just implement the one case and then you can test it. Right. So you don't even have to write a whole function at once. You can write the function incrementally. And that's one strategy that I do a lot in my programs. I'll say I'm not quite sure how we were working on a thing last night, actually, with 15, um, the grad student was actually programing that one, but I was, uh, I was committed and, um, and yeah, so I was suggesting, like, well, for this part, we could just do this thing. Um, so I just want to give you that advice as kind of general programmer practice. Um, oh, and you can return more than one thing from a function. You can return a struct, of course, but you can also or an object. But you can also use call by reference parameters passed by reference parameters. So that turns out to be really useful for things like keeping track of the parent of a node in a tree. Just just say it. Okay. Um, okay. So removal is going to start out like like insertion and contains basically, you know, we still have to negotiate the tree using the invariant to find the node. Um. And there are some easy cases. So the the two easy cases are empty tree roots. Not here. Nothing to do. Right. I'm done. I successfully deleted nothing. That's just good. Um, if it's a leaf, you can delete it. But you have to update. You have to update the pointer variable that had the address of the node you just deleted. Because otherwise a segmentation fault is in your future. Okay. Um, and depending on how you implement it, you, you, you know, you do need to be careful because the root, the root node doesn't have a parent. So that's the thing you have to keep track of. It's still a pointer variable. So it's not that hard really.

All right.

So let's go to the harder case. I was I thought today was a little bit short and I didn't put anything else on. It's going to be short. So, um, okay, so suppose we have one child, so 12. We already talked this through. Right? You know what to do. What do we do? Well, we have to hold on the address of the node containing 12 so we can delete it. But then we're going to update 17 so that it points to one. And it doesn't really matter whether it's the left or the right child. Right. Because anything to the left of 12 is less than 12 and certainly less than 17. But anything that's greater than 12 but is in the subtree where 12 is below 17 must be less than 17, because if it were greater than 17, it would be in this tree, this subtree. Right. So as long as there's one child, all you. So if the child were over here, then you could delete 12 and just bypass it that way. So it really doesn't matter. What matters is that there's one shot. So bypass and delete. Now, and notice that, uh, we're still having to update this address.

Questions.

Because you're going to do the hard disk.

Looks like the same. This one.

What's different? Oh, I didn't notice that. Okay. Um, right. So that just says what we do. Now life is hard. So I asked you to, uh. I asked you to let that simmer in your brain for a minute. And so now it's time to see what, if anything, has, uh, has resulted. Okay, so suppose we want to remove 17. Now, we've already figured out.

Um.

That we get to 17. And remember, we need to keep track of who was pointing the 17. Right. So you can have a reference to this thing. All right. So we want to remove this. Now we want to replace it with something that respects the um the binary search tree invariant. And what options are there.

But either the.

Rightmost note of the left subtree or the leftmost node of the right.

Interesting. Can you explain? So rightmost note of the left subtree. That would be this one. In this case.

S12
Because those ones are going to be the one that's.

Uh, that are greatest for least in that subtree. So the first part, then everything in the in the subtree and stay in the same place.

Yes. Okay. Excellent. So what we can do is if we remember, we didn't we do find men and find Max. So if we found the max in the left subtree. Well, by definition of max, it's larger than everything else in the subtree. Ignoring duplicates. Right. So that means if you put it here, everything in this tree is still good because they were less than 17. But the next best thing is the greatest thing among them. They're all less than that. So that'll work. Now, will it work over here? Well, it just has to be less than everything that's over here. Anything in the left subtree is less than everything. That's okay. We follow that. I'll say it again. So if we take the largest. So the left, everything in the left subtree of 17 is less than 17. Everything. If we take the largest value that's less than 17 and put it here, then because it was the largest value, it'll be larger than anything that remains in the tree in the left subtree, because that's what that's what max maximum means. Um, and because it's in the left subtree at all, it'll be less than these. So it'll, it'll preserve the invariant.

To avoid having to like move the pointers around. Could you just update the value of 17 to be 16 and then delete 16.

Yeah, that's what my code does.

Okay. So you don't accidentally you mentioned like you need to take the address the pointer from 35 to 17. But if you just update it then.

Oh that's true. So in principle we might have to do that. But in this case you're right. We don't really have to because we could just copy this data over here. But having done that we now need to do something else. We have to delete 60. Um, so that's the that's the trick. And um, taking the smallest value in the right subtree would also work. Oh sorry. Smallest value in the right subtree would also work, because anything in the right subtree is greater than anything over here. So anything over here go going into seventeens place which satisfied the invariant on the left. So that's not a problem. The trick is the right. But if we pick the smallest one, then because it's the smallest one, everything else on this side is less than. So if we move that up there, we'll be okay. All right. So the nice thing about this diagram is that the this the the ones we're picking are leaves, but they might not be leaves. Does the minimum and maximum have to be a leaf. Suppose two were in the tree over here. So the minimum is the leftmost node but it's not the leftmost leaf. Okay. Well so we've established that the leftmost node can have one child. Can it have two. You can't have two because then it wouldn't be leftmost. So the shape of the of the least, the shape of the node containing the least elements is either leaf or leaf with a jog to the greater side, because you can't have any more to the left side. Otherwise it's not the least element and you can't. And that's the that's the arithmetic argument. And then the geometric argument is things further left. This can't be the leftmost node if there are things further left. So you can think about it spatially. You can think about it in terms of values. Okay. But the good news is so what that means is that we have to delete whatever we put here. We have to delete. But it's not like one of these where we might have to go through the same process again. It will automatically be one of the two simple cases. Well, it'll be either it'll be leaf or, um, bypass. It'll be either the lead case or the bypass case. All right.

I think we.

Said everything, but let me just, um. Okay, so the trick is, if we if if we're going to take a thing from the tree and put it in Seventeens place, then it has to be something so that after we do that, everything to the left is less, everything to the right is greater. And that's true for all of the, um, nodes that we've seen. Um, and so the larger thing in the left subtree, so the, the largest of the smaller values, that's the, that's this one or the smallest of the larger values. So both of those are reasonable choices. They're both correct. Um. I think I said all that already. Um, and we're going to use that one. Just, uh, arbitrary choice. The other one's not wrong. It's just that, uh. Any examples you want to show? We want to be consistent. And if we ask you on an exam, you might say, okay, use this one, because it's easier than if you just if we all use the same one, but the other one is perfectly correct. Okay. So let's watch it in action. Um, so what we do is we we don't. Uh, okay. I just realized we're using the same notation for delete, so this node isn't deleted. Instead we're putting 16. So we'll replace it with 16. So we just took the value out of it. But then we have to recursively delete left from the tree we just pulled it out of. We have to we have to recursively remove 16 from the tree pulled it out of which means recursively remove 16 from the left subtree of that. And so then that gets. And we've already answered this question. Wow. Wow. Okay. This is much shorter than I thought. I figured I'd have about ten minutes, but I'm going to be almost done. All right. Well let's see. Um, okay. So here's the recap. Um, first find the node to remove. If it's empty, nothing to do. If it's a leaf, remove the leaf, update whatever was pointing to it. Um, if there's one child, um, you just you bypass the node by taking whatever was pointing to the node you make, point to the child, and then you delete the node. So there's a little bit more code involved because you've got to do this one. You've got to do that on the left and on the right. But they're the same basic pattern right. Just whichever one is non-empty. That's the thing that's going to that the parent should point to. Um, the hardest case is you have, um, two children, in which case you either take, um, the largest of the smaller values. So the, the rightmost from the left subtree, or the smallest of the larger values, the, which would be the rightmost of the left subtree weight. This is confusing because I'm facing you, right? So this is my right arm and this is my left arm. But this is my left arm from your point of view. So let me try this again. Um, we get to AVL tree. I need to practice anyway because with AVL this is going to come up a lot. Okay. So um, if I need to if, if I need to delete me and I've got two children I can take, I can, I can take um, this is the left subtree. So this is the lesser. So I can take the largest value from down here and replace me with it and then delete it from from there. Or I can take the smallest value from the greater sign. People who teach yoga and aerobics and stuff are really good at this. You know, they'll say, everybody raise your left hand and they'll pick up their right hand because, you know. It's a detail, but it's interesting. It's an interesting.

Story.

Unless you have a left right issue, which then it's fixed. It's not interesting. It's it's maddening. Um, okay.

So complexity.

Well, let's go through, uh, find the node to remove ordered tree height. Right.

UNKNOWN
Height of trees.

Uh, the easy cases. What do we think? Oh. Sorry. Question.

S11
Uh, I'm looking at the previous example. What if, uh, one had been, uh, a leaf 200? Sorry. Had a child. It was two. Um, the value two. Uh, in that case, would you call remove on one and like.

Yes. So you would replace 17 with one and then remove.

One which is.

S11
The same function. So it would just move two into one spot.

So then it would go.

Down and it would, it would bypass one. Yeah. And make 12 point to one directly and then delete.

This to two directly.

To. Yes. Yes. Perfect. You have an exact inverse. Okay. So complexity. Um these are all we those you guys haven't answered yet. Okay. So, uh, what is it, do you think?

All right.

Well, those are constant time. Um. That one's also constant time. Because you just have to update a pointer, the pointer variable, so that's not too bad. Um, this one is sort of interesting because, um, well, first of all, we have to call the max, which is again proportional to the height of the subtree, which we could sort of call in, um, and um, and then we have to do recursive removal which goes through those same steps. So it's ordered tree height again. So you would get so you would do sort of an order tree height thing. And then you would do another order tree height thing to find the minimum or maximum in the um the appropriate tree. And then you would have to do a delete on that tree, which again is order n but order n order an order n. How many times do you have to do it? Three. And you know you won't do it more than three because you know that the once you replace a node with a value from its left or right subtree. Um, the recursive delete is going to just do one traversal, it's going to find it and it's going to remove it in constant time. So the traversal is ordering. So we've got three um three ordered tree height I guess. So tree height. Well only one there. There's another one. Right. Because you have to you have to do the deletion. Um, and so we have the same story. It would be log n if everything's nice, but it's not nice. Um. So the answer is order tree height, which is order n.

Uh.

Okay. So, uh, quick summary. Um, binary search trees are cool and interesting. Once you think about them, they hold the promise of logarithmic time access to a huge amount of data, which is very cool, but we haven't realized it yet because binary Search tree by itself doesn't do that. But there are many variations of binary search trees that are called self-balancing binary search trees. That will get us that log behavior. And we're going to study one. We're going to study AVL trees. But there's a whole slew of them. Um there's a thing called generalized balanced trees. That one environment I use uses a lot. Uh so they're wide. So binary search trees are widely used in practice is the point. And so they're eminently worth knowing. And besides that, they're cool. And we'll figure out how to achieve ultimate balance. Um. We could do this. Yeah. Let's, uh. Should we do it?

Yeah. That's good. We can do it together.

Do we still have that thing there? Unfortunately.

Well, what just happened?

I don't know what happened. Okay. I've lost my mouse. There we.

Go.

All right, um. Try this. All right, so, um, I guess if I share the screen, then I can do this. So let me let me do that.

Okay.

So now we can have, uh, we can sort of have the proposed problem on the left and the display on the right. Okay. So let's insert 30. I don't think there's any mystery about how that goes. Um, where's 22 going to go? The left. Left. Excellent. Perfect.

Uh.

25 to the right.

To the right of 22. This is this is fun. Um, 45. Oh, I have to do this. 45. There you go. Because that's more than 30. 11. Let's see what.

Happens.

So another is less than 30. Less than 22. 40 is more than 30. Less than 45. This is nice.

S13
Um, 13. Where's 13? The right of 11 sounds good.

Because it's less mass. Greater.

S13
Perfect.

And 23 is going to go. It's going to be less greater or less. So let us do this quickly. Um, I urge you to when you do this, you can draw it by hand and then see if you if your picture agrees with the one on the website. Or you think 23. Hey, but we answered the question, what does it do? It goes to the right, which is same as our code.

It's pretty cool.

Um, okay, so I take it back.

Yeah. Uh. Oh.

No no no no no.

No no no.

Okay, well, let's remove 22 now.

Oh, what just.

Happened?

Uh, there were 222. So it looked it removed. The one that was closest to the root.

You're right. It did. Okay, so I said we weren't going to do duplicates. And I guess I, uh, I should have stuck by that. Okay, so now let's remove 22.

Okay. So. Yeah. Uh, this is fine.

Okay. Now we're going to delete 22. But think what's going to happen.

Uh.

So what's going to replace 22. Well either 13 or 23. But we said we picked the this one. So 13 is going to go.

Oh I think.

Oh. 25. That's not too bad. We're just going to update 13. So it points to the node containing. Store the bypass operation.

S13
And then you know what I.

Want to do I want to remove 30.

Yeah yeah.

Let's remove 30. So 23 is going to go there I guess.

All right.

Um, so uh.

S13
Just a minute.

Or two for questions and then.

Uh, because.

In that case it didn't seem about the. No, there was an extra because it just copied one down there. But what if we try to delete the node when it only has one, seven, three, click delete 45 and then try to delete delete. Again. So I guess in that case um.

I don't really.

But also.

That. There is. So we have.

Oh yeah.

But but that thing is you know. But but it is a.

Pointer.

Variable and.

It's pointer variable.

Oh yeah.

It's a variable of type application. So you can have a reference.

To a variable a pointer to a pointer to a node.

You can have the address of a.

Variable contains.

The address of.

Not in. This section. All right. Um so I.

Guess we're done early. Everybody go out and have fun.

Oh, really? Oh, really? Yeah. Okay, cool.

UNKNOWN
Okay. We don't expect that.

She's not. I don't think so. I would. Say so by order of attention. All the time. You get. Yes. You get a binary system.

It's probably come out of your mind.

I know that.

Well, I don't know. The only thing that.

I have an issue on.

Or that is to you both.

So, um.

It's a good.

Intuition. That's not how we're going to think about it.

Um, where this is going to come up for a different data structure.

I want to have another device or not.

But it has this mapping onto an array. So so we're going to. Oh. Um, so when I pointed that out, I just I was trying to point out just the joy you get when you realize if you took that pattern and sort of did this, you have a balanced binary search tree, which is just wonderful.

Like a very unbalanced binary search tree. You could theoretically turn this, like all the data, but this is absurdly like, oh no, I see.

Yeah.

This is totally like, uh.

Like I'm going to pack up.

Keep talking. Okay.

These are really like inefficient. But you can turn this into just an array with all the data and then order that array.

And you will already.

Be ordered. Then you can just grab the median and recreate the tree.

Uh, the thing is, until you don't traverse the whole thing, you won't. Yeah. If you.

If we do like if we do.

Like a.

Perfect, like left right traversal.

Oh yeah.

And then, and then we like and then we turn that into an array. And then we just delete the old tree, make a new tree with a new median.

Exactly. That was when I was like and as I mentioned like absurdly inefficient. But it will balance the tree like turn this into an array, order that array, and then use binary search. And with every single binary search, like creating a creator tree. Yeah, yeah.

You could you could absolutely do that. It is absurdly inefficient. Yes. Another observation is if the list is sorted, I said if you do the binary search you get the binary search tree, but it's a valid binary search tree. If this is the root and it just descends.

S14
It.

Is what, uh, we're trying to, like make it a.

Very nice binary search. Yeah, but it is one. Yeah. Um, okay. Oh, sorry. You had a different question. Yeah, I did.

A question about, um, the current project my My code has turned into just a large group like grouping of ID statements. Um, and.

Well, so just because.

Of all like the different function handling right.

Now, that's normal. So it's pretty typical where you have, uh. You know, an interactive thing like this where, you know, you're taking a thing to do, and then you have to say, well, which thing to do is it? And very often that becomes a bunch of if statements, if it's big one. A lot of people do this. We do a dispatch table. Do not do a dispatch table. Okay.

Um, yeah. I just split it up into, into different functions based on how many arguments they took.

Yeah. Okay. Um, just.

Like, oh, this one takes your arguments. So go to that function and then there's a bunch of statements in there that, that do things. And then I just go back if, if it was.

And this is just to avoid the function getting super long. Yeah. If the function is, you know, if it's a bit over 30 lines long, but it's all like it's two levels of indentation that look like this indent. If this indent thing else if thing else if thing else if thing. Um, we're mostly okay with that. Okay. I mean, the, the 30 line limit is the thing we're trying to sort of, um, for students to do is to keep the complexity level of a function now. Right. And the complexity level is a factor of more than one thing. But two things that are sort of syntactically apparent are length. Because the longer is, the more you have to read. Right. Um, but that tends.

Of like path.

But if it's highly structured, then.

That's really okay.

But if it's deeply nested then that's much more complicated. Yeah. So the 80 column rule forces you not to deeply nested.

It also forces you to take all your strings apart and put them on to different lines.

Well that's that that's not that's not a benefit.

That's a yeah that's it.

That's a sad consequence. But um, I really do mostly adhere to that rule. Um.

I most, I mostly adhere to the 80 column rule in my own code too. I just like, on occasion, need to have a string that's longer. And then.

Yeah, I.

Often break them up anyway just because I leave my, you know, I always have my Emacs window on the left of the screen, and I keep it at about 80, 85 columns. And then I have the rest of my screen. Yeah. And so I keep it that way just so that I don't have to like, keep resizing the window every time I load a new file or something. Right. Um. But yeah.

S13
So, um.

S15
The case of sort of a dispatch.